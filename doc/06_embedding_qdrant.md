# Embeddingãƒ»Qdrantç™»éŒ²ãƒ»æ¤œç´¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€Q/Aãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã®Embeddingï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰ã€Qdrantã¸ã®ç™»éŒ²ã€ãŠã‚ˆã³æ¤œç´¢å‡¦ç†ã«ã¤ã„ã¦è§£èª¬ã™ã‚‹ã€‚

## ç›®æ¬¡

- [1. æ¦‚è¦](#1-æ¦‚è¦)
  - [1.1 æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘](#11-æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘)
  - [1.2 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§](#12-é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§)
  - [1.3 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³](#13-ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³)
- [2. Embeddingï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰](#2-embeddingãƒ™ã‚¯ãƒˆãƒ«åŒ–)
  - [2.1 ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®š](#21-ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®š)
  - [2.2 embed_texts_for_qdrant() é–¢æ•°ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼](#22-embed_texts_for_qdrant-é–¢æ•°ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼)
  - [2.3 ãƒãƒƒãƒå‡¦ç†ã¨ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™](#23-ãƒãƒƒãƒå‡¦ç†ã¨ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™)
  - [2.4 åŸ‹ã‚è¾¼ã¿å…¥åŠ›ã®æ§‹ç¯‰ï¼ˆquestion + answerï¼‰](#24-åŸ‹ã‚è¾¼ã¿å…¥åŠ›ã®æ§‹ç¯‰question--answer)
  - [2.5 ç©ºæ–‡å­—åˆ—ãƒ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†](#25-ç©ºæ–‡å­—åˆ—ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†)
- [3. Qdrantç™»éŒ²](#3-qdrantç™»éŒ²)
  - [3.1 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­è¨ˆ](#31-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­è¨ˆ)
  - [3.2 ãƒ™ã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š](#32-ãƒ™ã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š)
  - [3.3 ãƒã‚¤ãƒ³ãƒˆæ§‹é€ ï¼ˆPointStructï¼‰](#33-ãƒã‚¤ãƒ³ãƒˆæ§‹é€ pointstruct)
  - [3.4 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ¼ãƒ](#34-ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ¼ãƒ)
  - [3.5 ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†](#35-ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†)
  - [3.6 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹](#36-ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
- [4. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ](#4-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ)
  - [4.1 çµ±åˆæ©Ÿèƒ½ã®æ¦‚è¦](#41-çµ±åˆæ©Ÿèƒ½ã®æ¦‚è¦)
  - [4.2 scroll_all_points_with_vectors()](#42-scroll_all_points_with_vectors)
  - [4.3 merge_collections()](#43-merge_collections)
  - [4.4 çµ±åˆæ™‚ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ](#44-çµ±åˆæ™‚ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ)
- [5. æ¤œç´¢å‡¦ç†](#5-æ¤œç´¢å‡¦ç†)
  - [5.1 ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–](#51-ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–)
  - [5.2 ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢](#52-ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢)
  - [5.3 æ¤œç´¢çµæœã®æ§‹é€ ](#53-æ¤œç´¢çµæœã®æ§‹é€ )
  - [5.4 AIå¿œç­”ç”Ÿæˆã¨ã®é€£æº](#54-aiå¿œç­”ç”Ÿæˆã¨ã®é€£æº)
- [6. é‹ç”¨ãƒ»è¨­å®š](#6-é‹ç”¨è¨­å®š)
  - [6.1 Qdrantè¨­å®šï¼ˆQDRANT_CONFIGï¼‰](#61-qdrantè¨­å®šqdrant_config)
  - [6.2 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆCRUDï¼‰](#62-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†crud)
  - [6.3 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯](#63-ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯)
  - [6.4 çµ±è¨ˆæƒ…å ±å–å¾—](#64-çµ±è¨ˆæƒ…å ±å–å¾—)
- [7. ä»˜éŒ²](#7-ä»˜éŒ²)
  - [7.1 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œè¡¨](#71-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¨csvãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œè¡¨)
  - [7.2 ã‚³ãƒ¼ãƒ‰å‚ç…§ä¸€è¦§](#72-ã‚³ãƒ¼ãƒ‰å‚ç…§ä¸€è¦§)

---

## 1. æ¦‚è¦

### 1.1 æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Œãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»Qdrantç™»éŒ²ãƒ»æ¤œç´¢ã€ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | ç„¦ç‚¹ | å†…å®¹ |
|-------------|------|------|
| `doc/03_chunk.md` | ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æŠ€è¡“ | SemanticCoverageã€æ–‡åˆ†å‰²ã€MeCab |
| `doc/04_prompt.md` | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ | 2æ®µéšæ§‹é€ ã€è¨€èªåˆ¥å¯¾å¿œã€å‹•çš„èª¿æ•´ |
| `doc/05_qa_pair.md` | å®Ÿè¡Œãƒ»å‡¦ç†ãƒ•ãƒ­ãƒ¼ | ä¸¦åˆ—å‡¦ç†ã€Celeryã€å‡ºåŠ›ã€ã‚«ãƒãƒ¬ãƒ¼ã‚¸ |
| `doc/06_embedding_qdrant.md`ï¼ˆæœ¬æ›¸ï¼‰ | ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»DBç™»éŒ²ãƒ»æ¤œç´¢ | Embeddingã€Qdrantã€é¡ä¼¼åº¦æ¤œç´¢ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ |

### 1.2 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

| ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² |
|---------|------|
| `services/qdrant_service.py` | Qdrantæ“ä½œã‚µãƒ¼ãƒ“ã‚¹å±¤ï¼ˆãƒ¡ã‚¤ãƒ³å®Ÿè£…ï¼‰ |
| `ui/pages/qdrant_registration_page.py` | ç™»éŒ²UIï¼ˆCSVç™»éŒ²ãƒ»ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆï¼‰ |
| `ui/pages/qdrant_search_page.py` | æ¤œç´¢UI |
| `ui/pages/qdrant_show_page.py` | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤ºUI |
| `a30_qdrant_registration.py` | CLIç™»éŒ²ã‚¹ã‚¯ãƒªãƒ—ãƒˆ |
| `a50_rag_search_local_qdrant.py` | CLIæ¤œç´¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ |

### 1.3 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³

```
[Q/Aãƒšã‚¢ãƒ‡ãƒ¼ã‚¿]
    â”‚
    â”‚ qa_output/*.csv (question, answeråˆ—)
    â–¼
[1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿]  â†â”€â”€ load_csv_for_qdrant()
    â”‚
    â”‚ DataFrame (question, answer)
    â–¼
[2. åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰]  â†â”€â”€ build_inputs_for_embedding()
    â”‚
    â”‚ List[str] ("question\nanswer" or "question")
    â–¼
[3. Embeddingç”Ÿæˆ]  â†â”€â”€ embed_texts_for_qdrant()
    â”‚
    â”‚ OpenAI API (text-embedding-3-small)
    â”‚ List[List[float]] (1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«)
    â–¼
[4. ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰]  â†â”€â”€ build_points_for_qdrant()
    â”‚
    â”‚ List[PointStruct] (id, vector, payload)
    â–¼
[5. Qdrantç™»éŒ²]  â†â”€â”€ upsert_points_to_qdrant()
    â”‚
    â”‚ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
    â–¼
[Qdrant Vector Database]
    â”‚
    â”œâ”€â”€[6a. æ¤œç´¢ã‚¯ã‚¨ãƒª]  â†â”€â”€ embed_query_for_search() + client.search()
    â”‚       â”‚
    â”‚       â”‚ ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢
    â”‚       â–¼
    â”‚   [æ¤œç´¢çµæœ] (score, question, answer, source)
    â”‚
    â””â”€â”€[6b. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ]  â†â”€â”€ merge_collections()
            â”‚
            â”‚ è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’1ã¤ã«çµ±åˆ
            â–¼
        [çµ±åˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³]
```

---

## 2. Embeddingï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰

### 2.1 ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®š

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€OpenAIã®`text-embedding-3-small`ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

```python
# services/qdrant_service.py - COLLECTION_EMBEDDINGS_SEARCH
DEFAULT_EMBEDDING_MODEL = "text-embedding-3-small"
DEFAULT_VECTOR_SIZE = 1536
```

| é …ç›® | å€¤ | èª¬æ˜ |
|-----|-----|-----|
| ãƒ¢ãƒ‡ãƒ« | text-embedding-3-small | OpenAIç¬¬3ä¸–ä»£åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« |
| æ¬¡å…ƒæ•° | 1536 | é«˜ç²¾åº¦ç‰ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ |
| ä»£æ›¿æ¬¡å…ƒæ•° | 384 | é«˜é€Ÿç‰ˆï¼ˆdimensionsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æŒ‡å®šå¯èƒ½ï¼‰ |
| ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° | cl100k_base | ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆç”¨ï¼ˆtiktokenï¼‰ |
| æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ | 8000 | ãƒãƒƒãƒå‡¦ç†ã®ä¸Šé™ |

**text-embedding-3ã‚·ãƒªãƒ¼ã‚ºã®ç‰¹å¾´:**

- å¯å¤‰æ¬¡å…ƒæ•°ã‚µãƒãƒ¼ãƒˆï¼ˆ384ã€œ3072ï¼‰
- ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«æœ€é©åŒ–
- å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªå«ã‚€ï¼‰
- text-embedding-ada-002ã®å¾Œç¶™

### 2.2 embed_texts_for_qdrant() é–¢æ•°ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼

```python
# services/qdrant_service.py:469-531
def embed_texts_for_qdrant(
    texts: List[str],
    model: str,
    batch_size: int = 128
) -> List[List[float]]:
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼å›³:**

```
[å…¥åŠ›: texts (List[str])]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ç©ºæ–‡å­—åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°           â”‚
â”‚    valid_texts = []                 â”‚
â”‚    valid_indices = []               â”‚
â”‚    for i, text in enumerate(texts): â”‚
â”‚        if text and text.strip():    â”‚
â”‚            valid_texts.append(text) â”‚
â”‚            valid_indices.append(i)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆï¼ˆtiktokenï¼‰      â”‚
â”‚    enc = tiktoken.get_encoding(     â”‚
â”‚        "cl100k_base"                â”‚
â”‚    )                                â”‚
â”‚    text_tokens = len(enc.encode(t)) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ãƒãƒƒãƒåˆ†å‰²                        â”‚
â”‚    MAX_TOKENS_PER_REQUEST = 8000    â”‚
â”‚    current_tokens + text_tokens     â”‚
â”‚        > MAX_TOKENS â†’ æ–°ãƒãƒƒãƒé–‹å§‹   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. OpenAI APIå‘¼ã³å‡ºã—               â”‚
â”‚    resp = client.embeddings.create( â”‚
â”‚        model=model,                 â”‚
â”‚        input=current_batch          â”‚
â”‚    )                                â”‚
â”‚    vecs = [d.embedding for d       â”‚
â”‚            in resp.data]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ãƒ™ã‚¯ãƒˆãƒ«å†é…ç½®                    â”‚
â”‚    å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦ä¸¦ã¹æ›¿ãˆ   â”‚
â”‚    ç©ºæ–‡å­—åˆ—ä½ç½®ã«ã¯                  â”‚
â”‚    [0.0] * 1536 ã®ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
[å‡ºåŠ›: List[List[float]] (1536æ¬¡å…ƒ Ã— Nä»¶)]
```

<details>
<summary>ğŸ“ embed_texts_for_qdrant() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:469-531

def embed_texts_for_qdrant(
    texts: List[str], model: str, batch_size: int = 128
) -> List[List[float]]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†ã§Embeddingã«å¤‰æ›"""
    enc = tiktoken.get_encoding("cl100k_base")
    client = OpenAI()

    MAX_TOKENS_PER_REQUEST = 8000

    # ç©ºæ–‡å­—åˆ—ãƒ»ç©ºç™½ã®ã¿ã®æ–‡å­—åˆ—ã‚’é™¤å¤–
    valid_texts = []
    valid_indices = []
    for i, text in enumerate(texts):
        if text and text.strip():
            valid_texts.append(text)
            valid_indices.append(i)

    if not valid_texts:
        logger.warning("å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºæ–‡å­—åˆ—ã§ã™ã€‚ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã—ã¾ã™ã€‚")
        return [[0.0] * 1536] * len(texts)

    # æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    valid_vecs: List[List[float]] = []
    current_batch = []
    current_tokens = 0
    batch_count = 0

    for i, text in enumerate(valid_texts):
        text_tokens = len(enc.encode(text))

        if text_tokens > MAX_TOKENS_PER_REQUEST:
            raise ValueError(
                f"Single text at index {valid_indices[i]} has {text_tokens} tokens, "
                f"which exceeds MAX_TOKENS_PER_REQUEST ({MAX_TOKENS_PER_REQUEST}). "
            )

        if current_tokens + text_tokens > MAX_TOKENS_PER_REQUEST:
            if current_batch:
                batch_count += 1
                resp = client.embeddings.create(model=model, input=current_batch)
                valid_vecs.extend([d.embedding for d in resp.data])
                current_batch = []
                current_tokens = 0

        current_batch.append(text)
        current_tokens += text_tokens

    if current_batch:
        batch_count += 1
        resp = client.embeddings.create(model=model, input=current_batch)
        valid_vecs.extend([d.embedding for d in resp.data])

    # å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†é…ç½®
    vecs: List[List[float]] = []
    valid_vec_idx = 0
    for i in range(len(texts)):
        if i in valid_indices:
            vecs.append(valid_vecs[valid_vec_idx])
            valid_vec_idx += 1
        else:
            vecs.append([0.0] * 1536)

    return vecs
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `tiktoken.get_encoding("cl100k_base")`: OpenAIåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ç”¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
- `MAX_TOKENS_PER_REQUEST = 8000`: APIåˆ¶é™ã«å¯¾å¿œã—ãŸãƒãƒƒãƒåˆ†å‰²
- ç©ºæ–‡å­—åˆ—ä½ç½®ã« `[0.0] * 1536` ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«é…ç½®ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ç¶­æŒï¼‰
- å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚º: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«å¿œã˜ã¦æœ€é©ãªãƒãƒƒãƒã‚’æ§‹ç¯‰

</details>

### 2.3 ãƒãƒƒãƒå‡¦ç†ã¨ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™

OpenAI Embedding APIã«ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚ãŸã‚Šã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ãŒã‚ã‚‹ã€‚

```python
MAX_TOKENS_PER_REQUEST = 8000
```

**ãƒãƒƒãƒåˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯:**

```python
for i, text in enumerate(valid_texts):
    text_tokens = len(enc.encode(text))

    # å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ¶é™ã‚’è¶…ãˆã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼
    if text_tokens > MAX_TOKENS_PER_REQUEST:
        raise ValueError(f"Single text has {text_tokens} tokens")

    # ç´¯ç©ãƒˆãƒ¼ã‚¯ãƒ³ãŒåˆ¶é™ã‚’è¶…ãˆãŸã‚‰æ–°ãƒãƒƒãƒé–‹å§‹
    if current_tokens + text_tokens > MAX_TOKENS_PER_REQUEST:
        # ç¾åœ¨ã®ãƒãƒƒãƒã‚’å‡¦ç†
        resp = client.embeddings.create(model=model, input=current_batch)
        valid_vecs.extend([d.embedding for d in resp.data])
        current_batch = []
        current_tokens = 0

    current_batch.append(text)
    current_tokens += text_tokens
```

**ãƒãƒƒãƒå‡¦ç†ã®åŠ¹ç‡:**

| ã‚·ãƒŠãƒªã‚ª | å¹³å‡ãƒ†ã‚­ã‚¹ãƒˆé•· | ãƒãƒƒãƒã‚µã‚¤ã‚ºç›®å®‰ | APIå‘¼ã³å‡ºã—å›æ•°ï¼ˆ1000ä»¶ï¼‰ |
|---------|--------------|----------------|------------------------|
| çŸ­æ–‡Q/A | 100ãƒˆãƒ¼ã‚¯ãƒ³ | 80ä»¶/ãƒãƒƒãƒ | ç´„13å› |
| ä¸­æ–‡Q/A | 300ãƒˆãƒ¼ã‚¯ãƒ³ | 26ä»¶/ãƒãƒƒãƒ | ç´„39å› |
| é•·æ–‡Q/A | 500ãƒˆãƒ¼ã‚¯ãƒ³ | 16ä»¶/ãƒãƒƒãƒ | ç´„63å› |

### 2.4 åŸ‹ã‚è¾¼ã¿å…¥åŠ›ã®æ§‹ç¯‰ï¼ˆquestion + answerï¼‰

Q/Aãƒšã‚¢ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹éš›ã€questionã®ã¿ã‹ã€question+answerã‹ã‚’é¸æŠã§ãã‚‹ã€‚

```python
# services/qdrant_service.py:462-466
def build_inputs_for_embedding(df: pd.DataFrame, include_answer: bool) -> List[str]:
    """åŸ‹ã‚è¾¼ã¿ç”¨å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
    if include_answer:
        # Q+Aã‚’é€£çµï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
        return (df["question"].astype(str) + "\n" + df["answer"].astype(str)).tolist()
    # questionã®ã¿
    return df["question"].astype(str).tolist()
```

**include_answerã®é¸æŠåŸºæº–:**

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | ç”¨é€” | ãƒ¡ãƒªãƒƒãƒˆ | ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ |
|-----------|------|---------|-----------|
| `include_answer=True` | å›ç­”å†…å®¹ã§ã®æ¤œç´¢ | æ¤œç´¢ç²¾åº¦å‘ä¸Šã€æ–‡è„ˆç†è§£ | ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚ºå¢—åŠ  |
| `include_answer=False` | è³ªå•ãƒãƒƒãƒãƒ³ã‚° | é«˜é€Ÿã€è³ªå•ã®é¡ä¼¼åº¦é‡è¦– | å›ç­”å†…å®¹ã‚’è€ƒæ…®ã—ãªã„ |

**æ¨å¥¨: `include_answer=True`**ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒå›ç­”å†…å®¹ã«è¿‘ã„å ´åˆã«æœ‰åŠ¹
- RAGã‚·ã‚¹ãƒ†ãƒ ã§ã¯å›ç­”ã®é–¢é€£æ€§ãŒé‡è¦

### 2.5 ç©ºæ–‡å­—åˆ—ãƒ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†

```python
# ç©ºæ–‡å­—åˆ—ã®å‡¦ç†
valid_texts = []
valid_indices = []
for i, text in enumerate(texts):
    if text and text.strip():  # ç©ºæ–‡å­—åˆ—ãƒ»ç©ºç™½ã®ã¿ã‚’é™¤å¤–
        valid_texts.append(text)
        valid_indices.append(i)

# å…¨ã¦ç©ºæ–‡å­—åˆ—ã®å ´åˆ
if not valid_texts:
    logger.warning("å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºæ–‡å­—åˆ—ã§ã™ã€‚ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã—ã¾ã™ã€‚")
    return [[0.0] * 1536] * len(texts)

# çµæœã®å†é…ç½®ï¼ˆç©ºæ–‡å­—åˆ—ä½ç½®ã«ã¯ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
vecs: List[List[float]] = []
valid_vec_idx = 0
for i in range(len(texts)):
    if i in valid_indices:
        vecs.append(valid_vecs[valid_vec_idx])
        valid_vec_idx += 1
    else:
        vecs.append([0.0] * 1536)  # ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«
```

**ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ« `[0.0] * 1536` ã®æ„å‘³:**
- ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã§ä»–ã®å…¨ã¦ã®ãƒ™ã‚¯ãƒˆãƒ«ã¨é¡ä¼¼åº¦0ã«ãªã‚‹
- æ¤œç´¢çµæœã«ç¾ã‚Œã«ãã„ï¼ˆæœ€ä½ã‚¹ã‚³ã‚¢ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ä¿æŒï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾å¿œï¼‰

---

## 3. Qdrantç™»éŒ²

### 3.1 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­è¨ˆ

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ç”Ÿæˆæ–¹å¼ã”ã¨ã«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†é›¢ã™ã‚‹ã€‚

**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‘½åè¦å‰‡:**

```
qa_{dataset}_{method}
```

| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | ç”Ÿæˆæ–¹å¼ |
|--------------|------------|---------|
| qa_cc_news_a02_llm | CC News | LLMç”Ÿæˆï¼ˆa02ï¼‰ |
| qa_cc_news_a03_rule | CC News | ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆa03ï¼‰ |
| qa_cc_news_a10_hybrid | CC News | ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼ˆa10ï¼‰ |
| qa_livedoor_a02_20_llm | Livedoor | LLMç”Ÿæˆï¼ˆa02ï¼‰ |
| qa_livedoor_a03_rule | Livedoor | ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆa03ï¼‰ |
| qa_livedoor_a10_hybrid | Livedoor | ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼ˆa10ï¼‰ |
| qa_corpus | ã‚«ã‚¹ã‚¿ãƒ  | æ±ç”¨ |
| integration_{name} | çµ±åˆ | è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ |

### 3.2 ãƒ™ã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

```python
# services/qdrant_service.py:534-562
def create_or_recreate_collection_for_qdrant(
    client: QdrantClient,
    name: str,
    recreate: bool = False,
    vector_size: int = 1536
):
    vectors_config = models.VectorParams(
        size=vector_size,
        distance=models.Distance.COSINE  # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
    )

    if recreate:
        try:
            client.delete_collection(collection_name=name)
        except Exception:
            pass
        client.create_collection(
            collection_name=name,
            vectors_config=vectors_config
        )
    else:
        # å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ä½œæˆ
        try:
            client.get_collection(name)
        except Exception:
            client.create_collection(
                collection_name=name,
                vectors_config=vectors_config
            )
```

**ãƒ™ã‚¯ãƒˆãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | èª¬æ˜ |
|-----------|-----|-----|
| size | 1536 | text-embedding-3-smallã®æ¬¡å…ƒæ•° |
| distance | COSINE | ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼ˆ-1ã€œ1ã€æ­£è¦åŒ–æ¸ˆã¿ï¼‰ |

**è·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é¸æŠ:**

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç¯„å›² | ç”¨é€” |
|-----------|------|------|
| COSINE | -1ã€œ1 | ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ï¼ˆæ¨å¥¨ï¼‰ |
| EUCLID | 0ã€œâˆ | çµ¶å¯¾è·é›¢ |
| DOT | -âˆã€œâˆ | éæ­£è¦åŒ–ãƒ™ã‚¯ãƒˆãƒ« |

### 3.3 ãƒã‚¤ãƒ³ãƒˆæ§‹é€ ï¼ˆPointStructï¼‰

Qdrantã®å„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤ã€‚

```python
# services/qdrant_service.py:565-589
def build_points_for_qdrant(
    df: pd.DataFrame,
    vectors: List[List[float]],
    domain: str,
    source_file: str
) -> List[models.PointStruct]:

    now_iso = datetime.now(timezone.utc).isoformat()
    points: List[models.PointStruct] = []

    for i, row in enumerate(df.itertuples(index=False)):
        payload = {
            "domain": domain,
            "question": getattr(row, "question"),
            "answer": getattr(row, "answer"),
            "source": os.path.basename(source_file),
            "created_at": now_iso,
            "schema": "qa:v1"
        }

        # IDã®ç”Ÿæˆï¼ˆ64ãƒ“ãƒƒãƒˆæ­£æ•´æ•°ï¼‰
        pid = abs(hash(f"{domain}-{source_file}-{i}")) & 0x7FFFFFFFFFFFFFFF

        points.append(models.PointStruct(
            id=pid,
            vector=vectors[i],
            payload=payload
        ))

    return points
```

**PointStructæ§‹é€ å›³:**

```
PointStruct
â”œâ”€â”€ id: int (64ãƒ“ãƒƒãƒˆæ­£æ•´æ•°)
â”‚       hash("domain-source_file-index") & 0x7FFFFFFFFFFFFFFF
â”‚
â”œâ”€â”€ vector: List[float] (1536æ¬¡å…ƒ)
â”‚       [0.0234, -0.1567, 0.0891, ...]
â”‚
â””â”€â”€ payload: Dict
        â”œâ”€â”€ domain: str        â†’ "livedoor", "cc_news", "custom"
        â”œâ”€â”€ question: str      â†’ "è³ªå•æ–‡ãƒ†ã‚­ã‚¹ãƒˆ"
        â”œâ”€â”€ answer: str        â†’ "å›ç­”æ–‡ãƒ†ã‚­ã‚¹ãƒˆ"
        â”œâ”€â”€ source: str        â†’ "a02_qa_pairs_livedoor.csv"
        â”œâ”€â”€ created_at: str    â†’ "2025-11-28T10:30:00+00:00"
        â””â”€â”€ schema: str        â†’ "qa:v1"
```

<details>
<summary>ğŸ“ build_points_for_qdrant() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:565-589

def build_points_for_qdrant(
    df: pd.DataFrame, vectors: List[List[float]], domain: str, source_file: str
) -> List[models.PointStruct]:
    """Qdrantãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰"""
    n = len(df)
    if len(vectors) != n:
        raise ValueError(f"vectors length mismatch: df={n}, vecs={len(vectors)}")

    now_iso = datetime.now(timezone.utc).isoformat()
    points: List[models.PointStruct] = []

    for i, row in enumerate(df.itertuples(index=False)):
        payload = {
            "domain": domain,
            "question": getattr(row, "question"),
            "answer": getattr(row, "answer"),
            "source": os.path.basename(source_file),
            "created_at": now_iso,
            "schema": "qa:v1",
        }

        # 64ãƒ“ãƒƒãƒˆæ­£æ•´æ•°IDç”Ÿæˆï¼ˆãƒãƒƒã‚·ãƒ¥è¡çªå›é¿ï¼‰
        pid = abs(hash(f"{domain}-{source_file}-{i}")) & 0x7FFFFFFFFFFFFFFF
        points.append(models.PointStruct(id=pid, vector=vectors[i], payload=payload))

    return points
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `& 0x7FFFFFFFFFFFFFFF`: 64ãƒ“ãƒƒãƒˆæ­£æ•´æ•°ã«å¤‰æ›ï¼ˆQdrantè¦ä»¶ï¼‰
- `datetime.now(timezone.utc).isoformat()`: UTCæ™‚åˆ»ã§ISO 8601å½¢å¼
- `schema: "qa:v1"`: ã‚¹ã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã§å°†æ¥ã®å¤‰æ›´ã«å¯¾å¿œ
- `os.path.basename(source_file)`: ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’ä¿å­˜ï¼ˆãƒ‘ã‚¹éä¾å­˜ï¼‰

</details>

### 3.4 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ¼ãƒ

**åŸºæœ¬ã‚¹ã‚­ãƒ¼ãƒï¼ˆqa:v1ï¼‰:**

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | å‹ | å¿…é ˆ | èª¬æ˜ |
|-----------|-----|------|-----|
| domain | string | âœ“ | ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆlivedoor, cc_news, customï¼‰ |
| question | string | âœ“ | è³ªå•æ–‡ |
| answer | string | âœ“ | å›ç­”æ–‡ |
| source | string | âœ“ | ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å |
| created_at | string | âœ“ | ç™»éŒ²æ—¥æ™‚ï¼ˆISO 8601ï¼‰ |
| schema | string | âœ“ | ã‚¹ã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆ"qa:v1"ï¼‰ |

**çµ±åˆæ™‚ã®è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:**

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | å‹ | èª¬æ˜ |
|-----------|-----|-----|
| _source_collection | string | çµ±åˆå…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å |
| _original_id | int | çµ±åˆå…ƒã§ã®å…ƒID |

### 3.5 ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†

```python
# services/qdrant_service.py:592-603
def upsert_points_to_qdrant(
    client: QdrantClient,
    collection: str,
    points: List[models.PointStruct],
    batch_size: int = 128
) -> int:
    """ãƒã‚¤ãƒ³ãƒˆã‚’Qdrantã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ"""
    count = 0
    for chunk in batched(points, batch_size):
        client.upsert(collection_name=collection, points=chunk)
        count += len(chunk)
    return count
```

**ãƒãƒƒãƒåˆ†å‰²ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£:**

```python
# services/qdrant_service.py:75-84
def batched(seq: Iterable, size: int):
    """ã‚¤ãƒ†ãƒ©ãƒ–ãƒ«ã‚’ãƒãƒƒãƒã«åˆ†å‰²"""
    buf = []
    for x in seq:
        buf.append(x)
        if len(buf) >= size:
            yield buf
            buf = []
    if buf:
        yield buf
```

**ãƒãƒƒãƒã‚µã‚¤ã‚ºã®é¸æŠ:**

| batch_size | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ | æ¨å¥¨ç”¨é€” |
|-----------|------------|------------|---------|
| 64 | ä½ | ä¸­ | ãƒ¡ãƒ¢ãƒªåˆ¶é™ç’°å¢ƒ |
| 128 | ä¸­ | é«˜ | **æ¨å¥¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰** |
| 256 | é«˜ | æœ€é«˜ | å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ |

**upsertã®å‹•ä½œ:**
- åŒä¸€IDãŒå­˜åœ¨ â†’ ä¸Šæ›¸ãæ›´æ–°
- æ–°è¦ID â†’ æ–°è¦æŒ¿å…¥
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çš„ãªå‹•ä½œï¼ˆãƒãƒƒãƒå˜ä½ï¼‰

### 3.6 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

æ¤œç´¢åŠ¹ç‡åŒ–ã®ãŸã‚ã€domainãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã€‚

```python
# create_or_recreate_collection_for_qdrant() å†…
try:
    client.create_payload_index(
        name,
        field_name="domain",
        field_schema=models.PayloadSchemaType.KEYWORD
    )
except Exception:
    pass  # æ—¢å­˜ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
```

**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åŠ¹æœ:**

```python
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—
client.search(collection_name="qa_corpus", query_vector=qvec, limit=5)
# â†’ å…¨ãƒã‚¤ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒ£ãƒ³

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚ã‚Š + ãƒ•ã‚£ãƒ«ã‚¿
client.search(
    collection_name="qa_corpus",
    query_vector=qvec,
    query_filter=models.Filter(
        must=[models.FieldCondition(
            key="domain",
            match=models.MatchValue(value="livedoor")
        )]
    ),
    limit=5
)
# â†’ domainã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
```

---

## 4. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ

### 4.1 çµ±åˆæ©Ÿèƒ½ã®æ¦‚è¦

è¤‡æ•°ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’1ã¤ã®æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«çµ±åˆã™ã‚‹æ©Ÿèƒ½ã€‚

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆæ¤œç´¢
- ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®æœ¬ç•ªçµ±åˆ
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ

**çµ±åˆãƒ•ãƒ­ãƒ¼å›³:**

```
[ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³A]     [ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³B]     [ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³C]
    â”‚                   â”‚                   â”‚
    â”‚ scroll()          â”‚ scroll()          â”‚ scroll()
    â–¼                   â–¼                   â–¼
[ãƒã‚¤ãƒ³ãƒˆå–å¾—]      [ãƒã‚¤ãƒ³ãƒˆå–å¾—]      [ãƒã‚¤ãƒ³ãƒˆå–å¾—]
    â”‚                   â”‚                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ IDå†ç”Ÿæˆ + payloadæ‹¡å¼µ
                        â–¼
              [çµ±åˆãƒã‚¤ãƒ³ãƒˆãƒªã‚¹ãƒˆ]
                        â”‚
                        â”‚ upsert()
                        â–¼
              [çµ±åˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³]
              integration_{name}
```

### 4.2 scroll_all_points_with_vectors()

ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å…¨ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«å«ã‚€ï¼‰ã‚’å–å¾—ã™ã‚‹ã€‚

```python
# services/qdrant_service.py:626-672
def scroll_all_points_with_vectors(
    client: QdrantClient,
    collection_name: str,
    batch_size: int = 100,
    progress_callback: Optional[callable] = None,
) -> List[models.Record]:
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å…¨ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«å«ã‚€ï¼‰ã‚’å–å¾—"""
    all_points = []
    offset = None

    # ç·ä»¶æ•°ã‚’å–å¾—
    collection_info = client.get_collection(collection_name)
    total_points = collection_info.points_count

    while True:
        points, next_offset = client.scroll(
            collection_name=collection_name,
            limit=batch_size,
            offset=offset,
            with_payload=True,
            with_vectors=True,  # ãƒ™ã‚¯ãƒˆãƒ«ã‚‚å–å¾—
        )

        if not points:
            break

        all_points.extend(points)

        if progress_callback:
            progress_callback(len(all_points), total_points)

        if next_offset is None:
            break

        offset = next_offset

    return all_points
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----|---------|------|
| client | QdrantClient | - | Qdrantã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ |
| collection_name | str | - | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å |
| batch_size | int | 100 | 1å›ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§å–å¾—ã™ã‚‹ä»¶æ•° |
| progress_callback | callable | None | é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ (å–å¾—æ¸ˆã¿, ç·ä»¶æ•°) |

### 4.3 merge_collections()

è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã—ã¦æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²ã™ã‚‹ã€‚

```python
# services/qdrant_service.py:675-779
def merge_collections(
    client: QdrantClient,
    source_collections: List[str],
    target_collection: str,
    recreate: bool = True,
    vector_size: int = 1536,
    progress_callback: Optional[callable] = None,
) -> Dict[str, Any]:
    """è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã—ã¦æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²"""
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----|---------|------|
| source_collections | List[str] | - | çµ±åˆå…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åãƒªã‚¹ãƒˆ |
| target_collection | str | - | çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å |
| recreate | bool | True | æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ |
| vector_size | int | 1536 | ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚º |
| progress_callback | callable | None | é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, ç¾åœ¨å€¤, æœ€å¤§å€¤) |

**æˆ»ã‚Šå€¤:**

```python
{
    "source_collections": ["qa_livedoor_a02", "qa_cc_news_a02"],
    "target_collection": "integration_qa_livedoor_a02",
    "points_per_collection": {
        "qa_livedoor_a02": 1500,
        "qa_cc_news_a02": 2000
    },
    "total_points": 3500,
    "success": True,
    "error": None
}
```

<details>
<summary>ğŸ“ merge_collections() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:675-779

def merge_collections(
    client: QdrantClient,
    source_collections: List[str],
    target_collection: str,
    recreate: bool = True,
    vector_size: int = 1536,
    progress_callback: Optional[callable] = None,
) -> Dict[str, Any]:
    """è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã—ã¦æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²"""
    result = {
        "source_collections": source_collections,
        "target_collection": target_collection,
        "points_per_collection": {},
        "total_points": 0,
        "success": False,
        "error": None,
    }

    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        if progress_callback:
            progress_callback(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{target_collection}' ã‚’ä½œæˆä¸­...", 0, 100)

        create_or_recreate_collection_for_qdrant(
            client, target_collection, recreate, vector_size
        )

        # ã‚¹ãƒ†ãƒƒãƒ—2: å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ã—ã¦çµ±åˆ
        all_points = []
        collection_count = len(source_collections)

        for idx, src_collection in enumerate(source_collections):
            if progress_callback:
                progress_callback(
                    f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{src_collection}' ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...",
                    int((idx / collection_count) * 50),
                    100,
                )

            # ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ï¼ˆãƒ™ã‚¯ãƒˆãƒ«å«ã‚€ï¼‰
            points = scroll_all_points_with_vectors(client, src_collection)
            result["points_per_collection"][src_collection] = len(points)

            # ãƒã‚¤ãƒ³ãƒˆIDã‚’å†ç”Ÿæˆï¼ˆé‡è¤‡å›é¿ï¼‰+ ã‚½ãƒ¼ã‚¹æƒ…å ±è¿½åŠ 
            for i, point in enumerate(points):
                payload = dict(point.payload) if point.payload else {}
                payload["_source_collection"] = src_collection
                payload["_original_id"] = point.id

                new_id = abs(
                    hash(f"{target_collection}-{src_collection}-{point.id}-{i}")
                ) & 0x7FFFFFFFFFFFFFFF

                all_points.append(
                    models.PointStruct(
                        id=new_id,
                        vector=point.vector,
                        payload=payload,
                    )
                )

        result["total_points"] = len(all_points)

        # ã‚¹ãƒ†ãƒƒãƒ—3: çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
        if progress_callback:
            progress_callback("çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­...", 50, 100)

        if all_points:
            upserted = 0
            batch_size = 128
            for chunk in batched(all_points, batch_size):
                client.upsert(collection_name=target_collection, points=chunk)
                upserted += len(chunk)
                if progress_callback:
                    progress = 50 + int((upserted / len(all_points)) * 50)
                    progress_callback(
                        f"ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­... ({upserted}/{len(all_points)})",
                        progress,
                        100,
                    )

        result["success"] = True

        if progress_callback:
            progress_callback("çµ±åˆå®Œäº†", 100, 100)

    except Exception as e:
        result["error"] = str(e)
        logger.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")

    return result
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `scroll_all_points_with_vectors()`: ãƒ™ã‚¯ãƒˆãƒ«ã‚’å«ã‚€å…¨ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
- `_source_collection` / `_original_id`: ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ç¢ºä¿ï¼ˆã©ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç”±æ¥ã‹è¿½è·¡å¯èƒ½ï¼‰
- æ–°IDãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ: `{target}-{src}-{original_id}-{index}` ã§è¡çªå›é¿
- `progress_callback`: 3æ®µéšã®é€²æ—é€šçŸ¥ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆâ†’ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆï¼‰
- ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ: 128ä»¶ãšã¤åˆ†å‰²ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

</details>

### 4.4 çµ±åˆæ™‚ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ

çµ±åˆæ™‚ã€å…ƒã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’æ‹¡å¼µã™ã‚‹ã€‚

```python
# ãƒã‚¤ãƒ³ãƒˆIDã‚’å†ç”Ÿæˆï¼ˆé‡è¤‡å›é¿ï¼‰
for i, point in enumerate(points):
    # å…ƒã®payloadã«ã‚½ãƒ¼ã‚¹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¿½åŠ 
    payload = dict(point.payload) if point.payload else {}
    payload["_source_collection"] = src_collection
    payload["_original_id"] = point.id

    # æ–°ã—ã„IDã‚’ç”Ÿæˆ
    new_id = abs(
        hash(f"{target_collection}-{src_collection}-{point.id}-{i}")
    ) & 0x7FFFFFFFFFFFFFFF

    all_points.append(
        models.PointStruct(
            id=new_id,
            vector=point.vector,
            payload=payload,
        )
    )
```

**çµ±åˆå¾Œã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ä¾‹:**

```python
{
    "domain": "livedoor",
    "question": "è³ªå•æ–‡",
    "answer": "å›ç­”æ–‡",
    "source": "a02_qa_pairs_livedoor.csv",
    "created_at": "2025-11-28T10:30:00+00:00",
    "schema": "qa:v1",
    "_source_collection": "qa_livedoor_a02",  # è¿½åŠ 
    "_original_id": 1234567890123456789       # è¿½åŠ 
}
```

---

## 5. æ¤œç´¢å‡¦ç†

### 5.1 ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–

æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚

```python
# services/qdrant_service.py:610-619
def embed_query_for_search(
    query: str,
    model: str = "text-embedding-3-small",
    dims: Optional[int] = None
) -> List[float]:
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    client = OpenAI()
    kwargs = {"model": model, "input": query}
    if dims:
        kwargs["dimensions"] = dims
    resp = client.embeddings.create(**kwargs)
    return resp.data[0].embedding
```

**embed_texts_for_qdrant() vs embed_query_for_search() ã®é•ã„:**

| é–¢æ•° | ç”¨é€” | ãƒãƒƒãƒ | ç©ºæ–‡å­—å‡¦ç† |
|-----|------|-------|----------|
| embed_texts_for_qdrant() | å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²æ™‚ | âœ“ | âœ“ |
| embed_query_for_search() | æ¤œç´¢ã‚¯ã‚¨ãƒª1ä»¶ | Ã— | Ã— |

### 5.2 ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢

```python
# Qdrantæ¤œç´¢ã®åŸºæœ¬å½¢
hits = client.search(
    collection_name=collection_name,
    query_vector=query_vector,
    limit=limit
)

results = []
for h in hits:
    results.append({
        "score": h.score,
        "id": h.id,
        "payload": h.payload
    })
```

**ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢:**

| ã‚¹ã‚³ã‚¢ | æ„å‘³ | è§£é‡ˆ |
|-------|------|------|
| 1.0 | å®Œå…¨ä¸€è‡´ | åŒä¸€ã¾ãŸã¯æ¥µã‚ã¦é¡ä¼¼ |
| 0.8ã€œ0.99 | é«˜é¡ä¼¼åº¦ | é–¢é€£æ€§ãŒé«˜ã„ |
| 0.5ã€œ0.79 | ä¸­é¡ä¼¼åº¦ | ã‚ã‚‹ç¨‹åº¦é–¢é€£ |
| 0.0ã€œ0.49 | ä½é¡ä¼¼åº¦ | é–¢é€£æ€§ãŒä½ã„ |
| < 0 | è² ã®ç›¸é–¢ | åå¯¾ã®æ„å‘³ |

### 5.3 æ¤œç´¢çµæœã®æ§‹é€ 

```python
# æ¤œç´¢çµæœã®ä¾‹
[
    {
        "score": 0.8923,
        "id": 1234567890123456789,
        "payload": {
            "domain": "livedoor",
            "question": "Pythonã§ãƒªã‚¹ãƒˆã‚’ã‚½ãƒ¼ãƒˆã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
            "answer": "sorted()é–¢æ•°ã¾ãŸã¯list.sort()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™...",
            "source": "a02_qa_pairs_livedoor.csv",
            "created_at": "2025-11-28T10:30:00+00:00",
            "schema": "qa:v1"
        }
    },
    {
        "score": 0.8456,
        "id": 9876543210987654321,
        "payload": {...}
    },
    ...
]
```

### 5.4 AIå¿œç­”ç”Ÿæˆã¨ã®é€£æº

æ¤œç´¢çµæœã‚’åŸºã«AIå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆRAGãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã€‚

```python
# ui/pages/qdrant_search_page.py
# æœ€é«˜ã‚¹ã‚³ã‚¢ã®æ¤œç´¢çµæœã‚’ä½¿ç”¨
best_hit = hits[0]
question = best_hit.payload.get("question", "")
answer = best_hit.payload.get("answer", "")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
qa_prompt = (
    "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦ã€"
    "æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
    f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
    f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
    f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
    f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
)

# OpenAI APIå‘¼ã³å‡ºã—
oai_client = OpenAI()
oai_resp = oai_client.responses.create(
    model="gpt-4o-mini",
    input=qa_prompt
)
generated_answer = oai_resp.output_text
```

<details>
<summary>ğŸ“ æ¤œç´¢ãƒ»AIå¿œç­”ç”Ÿæˆ å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# ui/pages/qdrant_search_page.py:160-267

# æ¤œç´¢å®Ÿè¡Œ
if do_search and query.strip():
    try:
        client = QdrantClient(url=qdrant_url)

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã—ãŸåŸ‹ã‚è¾¼ã¿è¨­å®šã‚’å–å¾—
        collection_config = COLLECTION_EMBEDDINGS_SEARCH.get(
            collection, {"model": "text-embedding-3-small", "dims": 1536}
        )
        embedding_model = collection_config["model"]
        embedding_dims = collection_config.get("dims")

        # ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        with st.spinner("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
            qvec = embed_query_for_search(query, embedding_model, embedding_dims)

        # Qdrantã§æ¤œç´¢
        with st.spinner("æ¤œç´¢ä¸­..."):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", DeprecationWarning)
                hits = client.search(
                    collection_name=collection, query_vector=qvec, limit=topk
                )

        # æ¤œç´¢çµæœã‚’DataFrameã«å¤‰æ›
        rows = []
        for h in hits:
            row_data = {
                "ã‚¹ã‚³ã‚¢": f"{h.score:.4f}",
                "è³ªå•": h.payload.get("question", "N/A") if h.payload else "N/A",
                "å›ç­”": h.payload.get("answer", "N/A") if h.payload else "N/A",
                "ã‚½ãƒ¼ã‚¹": h.payload.get("source", "N/A") if h.payload else "N/A",
            }
            rows.append(row_data)

        df_results = pd.DataFrame(rows)
        st.dataframe(df_results, use_container_width=True, hide_index=True)

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœã§AIå¿œç­”ç”Ÿæˆ
        if hits:
            best_hit = hits[0]
            question = best_hit.payload.get("question", "")
            answer = best_hit.payload.get("answer", "")

            # AIå¿œç­”ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            qa_prompt = (
                "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦ã€æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
                f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
                f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
                f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
                f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
            )

            # OpenAI APIå‘¼ã³å‡ºã—ï¼ˆresponses.createï¼‰
            with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                oai_client = OpenAI()
                oai_resp = oai_client.responses.create(
                    model="gpt-4o-mini", input=qa_prompt
                )
                generated_answer = (
                    getattr(oai_resp, "output_text", None) or ""
                )

            if generated_answer.strip():
                st.markdown("**AIå¿œç­”:**")
                st.write(generated_answer)

    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `embed_query_for_search()`: ã‚¯ã‚¨ãƒªã‚’1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
- `client.search()`: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§Top-Kæ¤œç´¢
- `responses.create()`: OpenAI Responses APIã§AIå¿œç­”ç”Ÿæˆ
- `getattr(oai_resp, "output_text", None)`: å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã®å®‰å…¨ãªå–å¾—
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: æ¥ç¶šã‚¨ãƒ©ãƒ¼ãƒ»ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœªæ¤œå‡ºã‚’å€‹åˆ¥å‡¦ç†

</details>

**RAGãƒ•ãƒ­ãƒ¼å›³:**

```
[ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•]
    â”‚
    â–¼
[1. ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ–] â† embed_query_for_search()
    â”‚
    â–¼
[2. Qdrantæ¤œç´¢] â† client.search()
    â”‚
    â”‚ Top-Kçµæœ (question, answer, score)
    â–¼
[3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰]
    â”‚
    â”‚ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ = è³ªå• + æ¤œç´¢çµæœ
    â–¼
[4. AIå¿œç­”ç”Ÿæˆ] â† OpenAI GPT-4o-mini
    â”‚
    â–¼
[æœ€çµ‚å›ç­”]
```

---

## 6. é‹ç”¨ãƒ»è¨­å®š

### 6.1 Qdrantè¨­å®šï¼ˆQDRANT_CONFIGï¼‰

```python
# services/qdrant_service.py:38-46
QDRANT_CONFIG = {
    "name": "Qdrant",
    "host": "localhost",
    "port": 6333,
    "icon": "ğŸ¯",
    "url": "http://localhost:6333",
    "health_check_endpoint": "/collections",
    "docker_image": "qdrant/qdrant",
}
```

**Qdrantèµ·å‹•æ–¹æ³•:**

```bash
# Docker Compose
docker-compose -f docker-compose/docker-compose.yml up -d

# ã¾ãŸã¯ç›´æ¥Docker
docker run -p 6333:6333 qdrant/qdrant

# ã‚µãƒ¼ãƒãƒ¼ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python server.py
```

### 6.2 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆCRUDï¼‰

**å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—:**

```python
# services/qdrant_service.py:377-397
def get_all_collections(client: QdrantClient) -> List[Dict[str, Any]]:
    collections = client.get_collections()
    collection_list = []

    for collection in collections.collections:
        info = client.get_collection(collection.name)
        collection_list.append({
            "name": collection.name,
            "points_count": info.points_count,
            "status": info.status,
        })

    return collection_list
```

**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ:**

```python
# services/qdrant_service.py:336-374
def get_collection_stats(client, collection_name) -> Optional[Dict]:
    collection_info = client.get_collection(collection_name)

    return {
        "total_points": collection_info.points_count,
        "vector_config": {
            "size": vectors_config.size,      # 1536
            "distance": str(vectors_config.distance)  # "Cosine"
        },
        "status": collection_info.status  # "green"
    }
```

**å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤:**

```python
# services/qdrant_service.py:400-424
def delete_all_collections(client, excluded: List[str] = None) -> int:
    excluded = excluded or []
    collections = get_all_collections(client)

    deleted_count = 0
    for col in collections:
        if col["name"] not in excluded:
            client.delete_collection(collection_name=col["name"])
            deleted_count += 1

    return deleted_count
```

### 6.3 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

```python
# services/qdrant_service.py:91-137
class QdrantHealthChecker:
    """Qdrantã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""

    def check_port(self, host: str, port: int, timeout: float = 2.0) -> bool:
        """ãƒãƒ¼ãƒˆãŒé–‹ã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        return result == 0

    def check_qdrant(self) -> Tuple[bool, str, Optional[Dict]]:
        """Qdrantæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        # ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        if not self.check_port(QDRANT_CONFIG["host"], QDRANT_CONFIG["port"]):
            return False, "Connection refused (port closed)", None

        # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        self.client = QdrantClient(url=QDRANT_CONFIG["url"], timeout=5)
        collections = self.client.get_collections()

        metrics = {
            "collection_count": len(collections.collections),
            "collections": [c.name for c in collections.collections],
            "response_time_ms": round((time.time() - start_time) * 1000, 2),
        }

        return True, "Connected", metrics
```

<details>
<summary>ğŸ“ QdrantHealthChecker å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:91-137

class QdrantHealthChecker:
    """Qdrantã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""

    def __init__(self, debug_mode: bool = False):
        self.debug_mode = debug_mode
        self.client = None

    def check_port(self, host: str, port: int, timeout: float = 2.0) -> bool:
        """ãƒãƒ¼ãƒˆãŒé–‹ã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((host, port))
            sock.close()
            return result == 0
        except Exception as e:
            if self.debug_mode:
                logger.error(f"Port check failed for {host}:{port}: {e}")
            return False

    def check_qdrant(self) -> Tuple[bool, str, Optional[Dict]]:
        """Qdrantæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        start_time = time.time()

        # ã¾ãšãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        if not self.check_port(QDRANT_CONFIG["host"], QDRANT_CONFIG["port"]):
            return False, "Connection refused (port closed)", None

        try:
            self.client = QdrantClient(url=QDRANT_CONFIG["url"], timeout=5)

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—
            collections = self.client.get_collections()

            metrics = {
                "collection_count": len(collections.collections),
                "collections": [c.name for c in collections.collections],
                "response_time_ms": round((time.time() - start_time) * 1000, 2),
            }

            return True, "Connected", metrics

        except Exception as e:
            error_msg = str(e)
            if self.debug_mode:
                error_msg = f"{error_msg}\n{traceback.format_exc()}"
            return False, error_msg, None
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `check_port()`: ã‚½ã‚±ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã§ãƒãƒ¼ãƒˆé–‹æ”¾ç¢ºèªï¼ˆé«˜é€Ÿãªäº‹å‰ãƒã‚§ãƒƒã‚¯ï¼‰
- `timeout=2.0`: ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã¯2ç§’ã€APIæ¥ç¶šã¯5ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
- `response_time_ms`: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ è¨ˆæ¸¬ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨ï¼‰
- `debug_mode`: ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ™‚ã«ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹è¡¨ç¤º

</details>

**ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ:**

```python
# æˆåŠŸæ™‚
(True, "Connected", {
    "collection_count": 6,
    "collections": ["qa_corpus", "qa_livedoor_a02_20_llm", ...],
    "response_time_ms": 12.34
})

# å¤±æ•—æ™‚
(False, "Connection refused (port closed)", None)
```

### 6.4 çµ±è¨ˆæƒ…å ±å–å¾—

**QdrantDataFetcher ã‚¯ãƒ©ã‚¹:**

```python
# services/qdrant_service.py:144-329
class QdrantDataFetcher:
    """Qdrantã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""

    def fetch_collections(self) -> pd.DataFrame:
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’DataFrameã§å–å¾—"""

    def fetch_collection_points(self, collection_name, limit=50) -> pd.DataFrame:
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""

    def fetch_collection_info(self, collection_name) -> Dict:
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""

    def fetch_collection_source_info(self, collection_name, sample_size=200) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆã‚½ãƒ¼ã‚¹åˆ¥ã®ä»¶æ•°ãƒ»å‰²åˆï¼‰"""
```

**ã‚½ãƒ¼ã‚¹æƒ…å ±ã®ä¾‹:**

```python
{
    "total_points": 1500,
    "sources": {
        "a02_qa_pairs_livedoor.csv": {
            "sample_count": 150,
            "method": "llm",
            "domain": "livedoor",
            "estimated_total": 1500,
            "percentage": 100.0
        }
    },
    "sample_size": 150
}
```

<details>
<summary>ğŸ“ fetch_collection_source_info() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:278-329

def fetch_collection_source_info(
    self, collection_name: str, sample_size: int = 200
) -> Dict[str, Any]:
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹æ¨å®šï¼‰"""
    try:
        collection_info = self.client.get_collection(collection_name)
        total_points = collection_info.points_count

        # ã‚µãƒ³ãƒ—ãƒ«ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
        points_result = self.client.scroll(
            collection_name=collection_name,
            limit=min(sample_size, total_points),
            with_payload=True,
            with_vectors=False,
        )
        points = points_result[0]

        # sourceã¨generation_methodã‚’é›†è¨ˆ
        source_stats = {}
        for point in points:
            if point.payload:
                source = point.payload.get("source", "unknown")
                method = point.payload.get("generation_method", "unknown")
                domain = point.payload.get("domain", "unknown")

                if source not in source_stats:
                    source_stats[source] = {
                        "sample_count": 0,
                        "method": method,
                        "domain": domain,
                    }
                source_stats[source]["sample_count"] += 1

        # å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿æ•°ã‚’æ¨å®š
        sample_total = len(points)
        for source, stats in source_stats.items():
            ratio = stats["sample_count"] / sample_total if sample_total > 0 else 0
            stats["estimated_total"] = int(total_points * ratio)
            stats["percentage"] = ratio * 100

        return {
            "total_points": total_points,
            "sources": source_stats,
            "sample_size": sample_total,
        }

    except Exception as e:
        logger.error(f"ã‚½ãƒ¼ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {"total_points": 0, "sources": {}, "sample_size": 0, "error": str(e)}
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `sample_size=200`: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å…¨ä½“ã‚’æ¨å®šï¼ˆé«˜é€ŸåŒ–ï¼‰
- `with_vectors=False`: ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®ã¿å–å¾—ï¼ˆå¸¯åŸŸå¹…ç¯€ç´„ï¼‰
- æ¯”ç‡è¨ˆç®—: `estimated_total = total_points * (sample_count / sample_total)`
- ã‚½ãƒ¼ã‚¹åˆ¥ã®çµ±è¨ˆ: ãƒ•ã‚¡ã‚¤ãƒ«åã€ç”Ÿæˆæ–¹å¼ã€ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±ã‚’é›†è¨ˆ

</details>

### 6.5 CSVâ†’Qdrantç™»éŒ²ãƒ•ãƒ­ãƒ¼ï¼ˆUIï¼‰

Streamlit UIã§ã®å®Œå…¨ãªç™»éŒ²ãƒ•ãƒ­ãƒ¼ã‚’ç¤ºã™ã€‚

**ç™»éŒ²ãƒ•ãƒ­ãƒ¼å›³:**

```
[CSVãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ]
    â”‚
    â”‚ qa_output/*.csv
    â–¼
[1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿]  â†â”€â”€ load_csv_for_qdrant()
    â”‚
    â”‚ DataFrame (question, answer)
    â–¼
[2. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ]  â†â”€â”€ create_or_recreate_collection_for_qdrant()
    â”‚
    â”‚ recreate=True/False
    â–¼
[3. åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰]  â†â”€â”€ build_inputs_for_embedding()
    â”‚
    â”‚ Q+Aé€£çµãƒ†ã‚­ã‚¹ãƒˆ
    â–¼
[4. åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ]  â†â”€â”€ embed_texts_for_qdrant()
    â”‚
    â”‚ 1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«
    â–¼
[5. ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰]  â†â”€â”€ build_points_for_qdrant()
    â”‚
    â”‚ PointStruct (id, vector, payload)
    â–¼
[6. ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ]  â†â”€â”€ upsert_points_to_qdrant()
    â”‚
    â–¼
[ç™»éŒ²å®Œäº†]
```

<details>
<summary>ğŸ“ CSVâ†’Qdrantç™»éŒ² å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# ui/pages/qdrant_registration_page.py:333-394

if run_registration:
    # CSVãƒ‘ã‚¹ã‚’æ§‹ç¯‰
    csv_path = Path("qa_output") / selected_csv

    if not csv_path.exists():
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        st.stop()

    try:
        client = QdrantClient(url=qdrant_url)

        # ã‚¹ãƒ†ãƒƒãƒ—1: CSVèª­ã¿è¾¼ã¿
        with st.spinner("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            df = load_csv_for_qdrant(str(csv_path), limit=data_limit)
            st.info(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} ä»¶")

        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
        with st.spinner(f"ğŸ“¦ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ã‚’æº–å‚™ä¸­..."):
            create_or_recreate_collection_for_qdrant(
                client, collection_name, recreate_collection
            )

        # ã‚¹ãƒ†ãƒƒãƒ—3: åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰
        with st.spinner("ğŸ“ åŸ‹ã‚è¾¼ã¿å…¥åŠ›ã‚’æ§‹ç¯‰ä¸­..."):
            texts = build_inputs_for_embedding(df, include_answer=True)

        # ã‚¹ãƒ†ãƒƒãƒ—4: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        progress_bar = st.progress(0)
        status_text = st.empty()

        with st.spinner("ğŸ§  åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
            vectors = embed_texts_for_qdrant(
                texts, model="text-embedding-3-small"
            )
            progress_bar.progress(50)
            status_text.text(f"åŸ‹ã‚è¾¼ã¿å®Œäº†: {len(vectors)} ä»¶")

        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰
        with st.spinner("ğŸ”§ Qdrantãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰ä¸­..."):
            points = build_points_for_qdrant(df, vectors, domain, selected_csv)

        # ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
        with st.spinner("ğŸ’¾ Qdrantã«ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ä¸­..."):
            count = upsert_points_to_qdrant(client, collection_name, points)
            progress_bar.progress(100)
            status_text.text(f"ç™»éŒ²å®Œäº†: {count} ä»¶")

        st.success(f"âœ… {count} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ '{collection_name}' ã«ç™»éŒ²ã—ã¾ã—ãŸ")

        # ç™»éŒ²å¾Œã®çµ±è¨ˆè¡¨ç¤º
        stats = get_collection_stats(client, collection_name)
        if stats:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ãƒã‚¤ãƒ³ãƒˆæ•°", stats["total_points"])
            with col2:
                st.metric("ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ", stats["vector_config"]["size"])
            with col3:
                st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", stats["status"])

    except Exception as e:
        st.error(f"âŒ ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {str(e)}")
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- 6ã‚¹ãƒ†ãƒƒãƒ—ã®ç™»éŒ²ãƒ•ãƒ­ãƒ¼ï¼ˆCSVãƒ­ãƒ¼ãƒ‰â†’ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆâ†’åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰â†’åŸ‹ã‚è¾¼ã¿ç”Ÿæˆâ†’ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰â†’ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆï¼‰
- `include_answer=True`: Q+Aé€£çµã§æ¤œç´¢ç²¾åº¦å‘ä¸Š
- `recreate_collection`: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦å†ç™»éŒ²ã™ã‚‹ã‹é¸æŠå¯èƒ½
- é€²æ—ãƒãƒ¼: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆâ†’ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆã§50%â†’100%
- ç™»éŒ²å¾Œã®çµ±è¨ˆè¡¨ç¤º: ãƒã‚¤ãƒ³ãƒˆæ•°ã€ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

</details>

---

## 7. ä»˜éŒ²

### 7.1 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œè¡¨

```python
# services/qdrant_service.py:60-68
COLLECTION_CSV_MAPPING = {
    "qa_corpus": "qa_pairs_corpus.csv",
    "qa_cc_news_a02_llm": "a02_qa_pairs_cc_news.csv",
    "qa_cc_news_a03_rule": "a03_qa_pairs_cc_news.csv",
    "qa_cc_news_a10_hybrid": "a10_qa_pairs_cc_news.csv",
    "qa_livedoor_a02_20_llm": "a02_qa_pairs_livedoor.csv",
    "qa_livedoor_a03_rule": "a03_qa_pairs_livedoor.csv",
    "qa_livedoor_a10_hybrid": "a10_qa_pairs_livedoor.csv",
}

# åŸ‹ã‚è¾¼ã¿è¨­å®š
# services/qdrant_service.py:49-57
COLLECTION_EMBEDDINGS_SEARCH = {
    "qa_corpus": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_cc_news_a02_llm": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_cc_news_a03_rule": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_cc_news_a10_hybrid": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_livedoor_a02_20_llm": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_livedoor_a03_rule": {"model": "text-embedding-3-small", "dims": 1536},
    "qa_livedoor_a10_hybrid": {"model": "text-embedding-3-small", "dims": 1536},
}
```

### 7.2 ã‚³ãƒ¼ãƒ‰å‚ç…§ä¸€è¦§

| æ©Ÿèƒ½ | ãƒ•ã‚¡ã‚¤ãƒ« | é–¢æ•°/ã‚¯ãƒ©ã‚¹ | è¡Œç•ªå· |
|-----|---------|------------|-------|
| Qdrantè¨­å®š | services/qdrant_service.py | QDRANT_CONFIG | 38-46 |
| ãƒãƒƒãƒåˆ†å‰² | services/qdrant_service.py | batched() | 75-84 |
| ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ | services/qdrant_service.py | QdrantHealthChecker | 91-137 |
| ãƒ‡ãƒ¼ã‚¿å–å¾— | services/qdrant_service.py | QdrantDataFetcher | 144-329 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ | services/qdrant_service.py | get_collection_stats() | 336-374 |
| å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾— | services/qdrant_service.py | get_all_collections() | 377-397 |
| å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤ | services/qdrant_service.py | delete_all_collections() | 400-424 |
| CSVèª­ã¿è¾¼ã¿ | services/qdrant_service.py | load_csv_for_qdrant() | 431-459 |
| åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰ | services/qdrant_service.py | build_inputs_for_embedding() | 462-466 |
| åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆãƒãƒƒãƒï¼‰ | services/qdrant_service.py | embed_texts_for_qdrant() | 469-531 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ | services/qdrant_service.py | create_or_recreate_collection_for_qdrant() | 534-562 |
| ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ | services/qdrant_service.py | build_points_for_qdrant() | 565-589 |
| ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ | services/qdrant_service.py | upsert_points_to_qdrant() | 592-603 |
| æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ– | services/qdrant_service.py | embed_query_for_search() | 610-619 |
| å…¨ãƒã‚¤ãƒ³ãƒˆå–å¾— | services/qdrant_service.py | scroll_all_points_with_vectors() | 626-672 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ | services/qdrant_service.py | merge_collections() | 675-779 |
| ç™»éŒ²UI | ui/pages/qdrant_registration_page.py | show_qdrant_registration_page() | 39-600 |
| æ¤œç´¢UI | ui/pages/qdrant_search_page.py | show_qdrant_search_page() | - |