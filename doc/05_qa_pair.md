# Q/Aãƒšã‚¢ç”Ÿæˆå‡¦ç†ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€RAG Q/Aç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹Q/Aãƒšã‚¢ç”Ÿæˆã®å®Ÿè¡Œãƒ»å‡¦ç†ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦è§£èª¬ã™ã‚‹ã€‚

## ç›®æ¬¡

- [1. æ¦‚è¦](#1-æ¦‚è¦)
  - [1.1 æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘](#11-æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘)
  - [1.2 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§](#12-é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§)
  - [1.3 Q/Aç”Ÿæˆå‡¦ç†ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼å›³](#13-qaç”Ÿæˆå‡¦ç†ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼å›³)
- [2. a02_make_qa_para.py ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼](#2-a02_make_qa_parapy-ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼)
  - [2.1 ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ä¸€è¦§](#21-ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ä¸€è¦§)
  - [2.2 å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°](#22-å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°)
  - [2.3 åŒæœŸå‡¦ç† vs éåŒæœŸå‡¦ç†ã®é¸æŠ](#23-åŒæœŸå‡¦ç†-vs-éåŒæœŸå‡¦ç†ã®é¸æŠ)
- [3. éåŒæœŸä¸¦åˆ—å‡¦ç†ã®å¿…è¦æ€§](#3-éåŒæœŸä¸¦åˆ—å‡¦ç†ã®å¿…è¦æ€§)
  - [3.1 Q/Aç”Ÿæˆå‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯](#31-qaç”Ÿæˆå‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯)
  - [3.2 ä¸¦åˆ—åŒ–ãŒæœ‰åŠ¹ãªç†ç”±](#32-ä¸¦åˆ—åŒ–ãŒæœ‰åŠ¹ãªç†ç”±)
  - [3.3 ä¸¦åˆ—åŒ–ã«ã‚ˆã‚‹åŠ¹æœ](#33-ä¸¦åˆ—åŒ–ã«ã‚ˆã‚‹åŠ¹æœ)
- [4. Celeryä¸¦åˆ—å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#4-celeryä¸¦åˆ—å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
  - [4.1 ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³](#41-ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³)
  - [4.2 ä¸¦åˆ—åŒ–ã•ã‚Œã‚‹å…·ä½“çš„ãªå‡¦ç†](#42-ä¸¦åˆ—åŒ–ã•ã‚Œã‚‹å…·ä½“çš„ãªå‡¦ç†)
  - [4.3 ã‚¿ã‚¹ã‚¯è¨­è¨ˆè©³ç´°](#43-ã‚¿ã‚¹ã‚¯è¨­è¨ˆè©³ç´°)
  - [4.4 ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°](#44-ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°)
  - [4.5 çµæœåé›†ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆRedisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ï¼‰](#45-çµæœåé›†ãƒ¡ã‚«ãƒ‹ã‚ºãƒ redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹)
  - [4.6 ãƒªãƒˆãƒ©ã‚¤ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#46-ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
- [5. å‡ºåŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜](#5-å‡ºåŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜)
  - [5.1 å‡ºåŠ›å½¢å¼](#51-å‡ºåŠ›å½¢å¼)
  - [5.2 ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡](#52-ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡)
  - [5.3 ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸](#53-ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸)
  - [5.4 ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ](#54-ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ )
- [6. ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ](#6-ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ)
  - [6.1 ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã®æ¦‚å¿µã¨ç›®çš„](#61-ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã®æ¦‚å¿µã¨ç›®çš„)
  - [6.2 è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ](#62-è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ )
  - [6.3 é–¾å€¤è¨­å®šã¨èª¿æ•´](#63-é–¾å€¤è¨­å®šã¨èª¿æ•´)
  - [6.4 åˆ†æçµæœã®è§£é‡ˆ](#64-åˆ†æçµæœã®è§£é‡ˆ)
- [7. UIã‹ã‚‰ã®å®Ÿè¡Œï¼ˆStreamlitï¼‰](#7-uiã‹ã‚‰ã®å®Ÿè¡Œstreamlit)
  - [7.1 qa_generation_page.pyã®æ§‹é€ ](#71-qa_generation_pagepyã®æ§‹é€ )
  - [7.2 å…¥åŠ›ã‚½ãƒ¼ã‚¹é¸æŠ](#72-å…¥åŠ›ã‚½ãƒ¼ã‚¹é¸æŠ)
  - [7.3 è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³](#73-è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³)
  - [7.4 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º](#74-ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º)
- [8. å®Ÿè¡Œä¾‹ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#8-å®Ÿè¡Œä¾‹ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
  - [8.1 å…¸å‹çš„ãªå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰](#81-å…¸å‹çš„ãªå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰)
  - [8.2 ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦](#82-ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦)
  - [8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](#83-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)
- [å‚è€ƒè³‡æ–™](#å‚è€ƒè³‡æ–™)

---

## 1. æ¦‚è¦

### 1.1 æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¥ã‘

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€ŒQ/Aãƒšã‚¢ç”Ÿæˆã®å®Ÿè¡Œãƒ»å‡¦ç†ãƒ•ãƒ­ãƒ¼ã€ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | ç„¦ç‚¹ | å†…å®¹ |
|-------------|------|------|
| `doc/01_chunk.md` | ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æŠ€è¡“ | SemanticCoverageã€æ–‡åˆ†å‰²ã€MeCab |
| `doc/02_prompt.md` | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ | 2æ®µéšæ§‹é€ ã€è¨€èªåˆ¥å¯¾å¿œã€å‹•çš„èª¿æ•´ |
| `doc/03_qa_pair.md`ï¼ˆæœ¬æ›¸ï¼‰ | å®Ÿè¡Œãƒ»å‡¦ç†ãƒ•ãƒ­ãƒ¼ | ä¸¦åˆ—å‡¦ç†ã€Celeryã€å‡ºåŠ›ã€ã‚«ãƒãƒ¬ãƒ¼ã‚¸ |

### 1.2 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

| ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² |
|---------|------|
| `a02_make_qa_para.py` | Q/Aç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ |
| `celery_tasks.py` | CeleryéåŒæœŸã‚¿ã‚¹ã‚¯å®šç¾© |
| `config.py` | è¨­å®šç®¡ç†ï¼ˆCeleryè¨­å®šå«ã‚€ï¼‰ |
| `models.py` | Pydanticãƒ¢ãƒ‡ãƒ«ï¼ˆQAPairç­‰ï¼‰ |
| `services/qa_service.py` | UIã‹ã‚‰ã®ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ |
| `ui/pages/qa_generation_page.py` | Streamlit UI |

### 1.3 Q/Aç”Ÿæˆå‡¦ç†ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼å›³

```
[å…¥åŠ›ãƒ‡ãƒ¼ã‚¿]
    â”‚
    â”œâ”€â”€ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆcc_news, livedoorç­‰ï¼‰
    â””â”€â”€ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSV, JSON, TXTï¼‰
    â”‚
    â–¼
[1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿]  â†â”€â”€ load_preprocessed_data() / load_uploaded_file()
    â”‚
    â–¼
[2. ãƒãƒ£ãƒ³ã‚¯ä½œæˆ]  â†â”€â”€ create_document_chunks()
    â”‚                    â””â”€â”€ SemanticCoverage.create_semantic_chunks()
    â”‚                        ï¼ˆè©³ç´°ã¯ doc/01_chunk.md å‚ç…§ï¼‰
    â”‚
    â–¼
[3. ãƒãƒ£ãƒ³ã‚¯å‰å‡¦ç†]  â†â”€â”€ merge_small_chunks()
    â”‚                    å°ãƒãƒ£ãƒ³ã‚¯çµ±åˆï¼ˆmin_tokensæœªæº€ã‚’çµ±åˆï¼‰
    â”‚
    â–¼
[4. Q/Aç”Ÿæˆ]  â†â”€â”€ åŒæœŸ or éåŒæœŸï¼ˆCeleryï¼‰
    â”‚              ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°ã¯ doc/02_prompt.md å‚ç…§ï¼‰
    â”‚
    â”œâ”€â”€ ã€åŒæœŸå‡¦ç†ã€‘generate_qa_for_dataset()
    â”‚       â””â”€â”€ generate_qa_pairs_for_batch()
    â”‚
    â””â”€â”€ ã€éåŒæœŸå‡¦ç†ã€‘Celeryä¸¦åˆ—å‡¦ç†
            â”œâ”€â”€ submit_parallel_qa_generation()
            â”œâ”€â”€ generate_qa_for_chunk_async() / generate_qa_for_batch_async()
            â””â”€â”€ collect_results()
    â”‚
    â–¼
[5. ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ]  â†â”€â”€ analyze_coverage()ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    â”‚
    â–¼
[6. çµæœä¿å­˜]  â†â”€â”€ save_results()
    â”‚
    â–¼
[å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«]
    â”œâ”€â”€ qa_pairs_{dataset}_{timestamp}.json
    â”œâ”€â”€ qa_pairs_{dataset}_{timestamp}.csv
    â”œâ”€â”€ coverage_{dataset}_{timestamp}.json
    â””â”€â”€ summary_{dataset}_{timestamp}.json
```

---

## 2. a02_make_qa_para.py ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼

### 2.1 ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ä¸€è¦§

| å¼•æ•° | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|------|-----------|------|
| `--dataset` | ãªã— | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆcc_news, livedoorç­‰ï¼‰ |
| `--input-file` | ãªã— | ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ--datasetã¨æ’ä»–ï¼‰ |
| `--model` | gpt-4o-mini | ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ« |
| `--output` | qa_output/a02 | å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
| `--max-docs` | ãªã— | å‡¦ç†ã™ã‚‹æœ€å¤§æ–‡æ›¸æ•° |
| `--batch-chunks` | 3 | 1å›ã®APIã§å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯æ•°ï¼ˆ1-5ï¼‰ |
| `--merge-chunks` | æœ‰åŠ¹ | å°ãƒãƒ£ãƒ³ã‚¯çµ±åˆã‚’æœ‰åŠ¹åŒ– |
| `--min-tokens` | 150 | çµ±åˆå¯¾è±¡ã®æœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•° |
| `--max-tokens` | 400 | çµ±åˆå¾Œã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•° |
| `--use-celery` | ç„¡åŠ¹ | Celeryä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨ |
| `--celery-workers` | 4 | Celeryãƒ¯ãƒ¼ã‚«ãƒ¼æ•° |
| `--analyze-coverage` | ç„¡åŠ¹ | ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æã‚’å®Ÿè¡Œ |
| `--coverage-threshold` | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ | ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ¤å®šé–¾å€¤ |

### 2.2 å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°

#### Step 1: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹èª­ã¿è¾¼ã¿

```python
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å ´åˆ
df = load_preprocessed_data(dataset_type)
# â†’ OUTPUT/preprocessed_{dataset}.csv ã‚’èª­ã¿è¾¼ã¿

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
df = load_uploaded_file(args.input_file)
# â†’ CSV/JSON/JSONL/TXT ã«å¯¾å¿œ
# â†’ Combined_Text ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•ç”Ÿæˆ
```

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:704-753`ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã€`545-640`ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

#### Step 2: ãƒãƒ£ãƒ³ã‚¯åŒ–

```python
chunks = create_document_chunks(df, dataset_type, max_docs, config)
```

å†…éƒ¨ã§ `SemanticCoverage.create_semantic_chunks()` ã‚’å‘¼ã³å‡ºã—ã€æ®µè½å„ªå…ˆã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†å‰²ã‚’å®Ÿè¡Œã€‚

**è©³ç´°**: `doc/01_chunk.md` å‚ç…§

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:756-816`

#### Step 3: Q/Aç”Ÿæˆ

åŒæœŸå‡¦ç†ã¾ãŸã¯éåŒæœŸå‡¦ç†ï¼ˆCeleryï¼‰ã‚’é¸æŠã€‚

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:2036-2079`

#### Step 4: çµæœä¿å­˜

```python
saved_files = save_results(qa_pairs, coverage_results, dataset_type, output_dir)
```

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:1776-1859`

### 2.3 åŒæœŸå‡¦ç† vs éåŒæœŸå‡¦ç†ã®é¸æŠ

| è¦³ç‚¹ | åŒæœŸå‡¦ç† | éåŒæœŸå‡¦ç†ï¼ˆCeleryï¼‰ |
|------|---------|---------------------|
| ä½¿ç”¨å ´é¢ | å°‘é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆ~100ãƒãƒ£ãƒ³ã‚¯ï¼‰ | å¤§é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆ100+ãƒãƒ£ãƒ³ã‚¯ï¼‰ |
| å‡¦ç†é€Ÿåº¦ | é…ã„ï¼ˆé€æ¬¡å®Ÿè¡Œï¼‰ | é«˜é€Ÿï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰ |
| è¨­å®š | ä¸è¦ | Redis + Celeryãƒ¯ãƒ¼ã‚«ãƒ¼å¿…è¦ |
| ã‚¨ãƒ©ãƒ¼æ™‚ | å…¨ä½“åœæ­¢ | ä»–ã‚¿ã‚¹ã‚¯ã¯ç¶™ç¶š |
| æ¨å¥¨ | ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚° | æœ¬ç•ªå®Ÿè¡Œ |

---

## 3. éåŒæœŸä¸¦åˆ—å‡¦ç†ã®å¿…è¦æ€§

### 3.1 Q/Aç”Ÿæˆå‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯

Q/Aç”Ÿæˆå‡¦ç†ã®ä¸»ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ **OpenAI APIå‘¼ã³å‡ºã—ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** ã§ã‚ã‚‹ã€‚

| é …ç›® | å€¤ |
|------|-----|
| 1å›ã®APIå‘¼ã³å‡ºã— | 2-5ç§’ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶å«ã‚€ï¼‰ |
| 1ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚ŠQ/Aç”Ÿæˆ | ç´„3ç§’ |
| 1000ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆåŒæœŸï¼‰ | ç´„50åˆ† |

#### è¨ˆç®—ä¾‹

```
ã€åŒæœŸå‡¦ç†ã®å ´åˆã€‘
1000ãƒãƒ£ãƒ³ã‚¯ Ã— 3ç§’/ãƒãƒ£ãƒ³ã‚¯ = 3000ç§’ = 50åˆ†

ã€ãƒãƒƒãƒå‡¦ç†ï¼ˆ3ãƒãƒ£ãƒ³ã‚¯/APIï¼‰ã®å ´åˆã€‘
1000ãƒãƒ£ãƒ³ã‚¯ Ã· 3 = 334 APIå‘¼ã³å‡ºã—
334 Ã— 3ç§’ = 1002ç§’ â‰’ 17åˆ†

ã€Celeryä¸¦åˆ—å‡¦ç†ï¼ˆ24ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰ã®å ´åˆã€‘
334 APIå‘¼ã³å‡ºã— Ã· 24ãƒ¯ãƒ¼ã‚«ãƒ¼ â‰’ 14 ãƒ©ã‚¦ãƒ³ãƒ‰
14 Ã— 3ç§’ = 42ç§’ + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ â‰’ 2-3åˆ†
```

**ä¸¦åˆ—åŒ–ãŒæœ‰åŠ¹ãªç†ç”±:**
- å„ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹
- OpenAI APIå‘¼ã³å‡ºã—ã¯I/Oãƒã‚¦ãƒ³ãƒ‰ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾…ã¡ï¼‰
- 1å›ã®APIå‘¼ã³å‡ºã—ã«2-5ç§’ã‹ã‹ã‚‹
- 1000ãƒãƒ£ãƒ³ã‚¯ Ã— 3ç§’ = 50åˆ† â†’ 24ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ç´„2-3åˆ†ã«çŸ­ç¸®

### 3.2 ä¸¦åˆ—åŒ–ãŒæœ‰åŠ¹ãªç†ç”±

#### ç†ç”±1: å„ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†ãŒç‹¬ç«‹

```
ãƒãƒ£ãƒ³ã‚¯A ã®Q/Aç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”
ãƒãƒ£ãƒ³ã‚¯B ã®Q/Aç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ çµæœçµ±åˆ
ãƒãƒ£ãƒ³ã‚¯C ã®Q/Aç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”˜

â€» å„ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†çµæœã¯ä»–ã«ä¾å­˜ã—ãªã„
```

#### ç†ç”±2: I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†

```
ã€CPUå‡¦ç†ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ â”‚ â† é«˜é€Ÿï¼ˆãƒŸãƒªç§’ï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€I/Oå¾…ã¡ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI APIå‘¼ã³å‡ºã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â† é…ã„ï¼ˆç§’å˜ä½ï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€CPUå‡¦ç†ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ â”‚ â† é«˜é€Ÿï¼ˆãƒŸãƒªç§’ï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â€» å‡¦ç†æ™‚é–“ã®95%ä»¥ä¸ŠãŒI/Oå¾…ã¡
â€» I/Oå¾…ã¡ä¸­ã«CPUã¯éŠã‚“ã§ã„ã‚‹ â†’ ä¸¦åˆ—åŒ–ã§æœ‰åŠ¹æ´»ç”¨
```

#### ç†ç”±3: ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå¯èƒ½

ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§ã€å‡¦ç†æ™‚é–“ã‚’ç·šå½¢ã«çŸ­ç¸®ã§ãã‚‹ã€‚

| ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° | 1000ãƒãƒ£ãƒ³ã‚¯å‡¦ç†æ™‚é–“ï¼ˆæ¨å®šï¼‰ |
|-----------|---------------------------|
| 1 | 50åˆ† |
| 4 | 12-15åˆ† |
| 8 | 6-8åˆ† |
| 16 | 3-4åˆ† |
| 24 | 2-3åˆ† |

### 3.3 ä¸¦åˆ—åŒ–ã«ã‚ˆã‚‹åŠ¹æœ

| åŠ¹æœ | èª¬æ˜ |
|------|------|
| **å‡¦ç†æ™‚é–“ã®çŸ­ç¸®** | 24ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ç´„1/20ã«çŸ­ç¸® |
| **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š** | å˜ä½æ™‚é–“ã‚ãŸã‚Šã®å‡¦ç†é‡ãŒå¢—åŠ  |
| **ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®æœ€å¤§åŒ–** | CPU/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åŠ¹ç‡çš„ã«åˆ©ç”¨ |
| **è€éšœå®³æ€§** | 1ã‚¿ã‚¹ã‚¯å¤±æ•—ã—ã¦ã‚‚ä»–ã‚¿ã‚¹ã‚¯ã¯ç¶™ç¶š |
| **ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½** | å¤±æ•—ã‚¿ã‚¹ã‚¯ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§3å›ï¼‰ |

---

## 4. Celeryä¸¦åˆ—å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 4.1 ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹                               â”‚
â”‚                     (a02_make_qa_para.py)                          â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ ãƒãƒ£ãƒ³ã‚¯    â”‚     â”‚ submit_parallel_    â”‚                       â”‚
â”‚  â”‚ ä½œæˆ       â”‚ â”€â”€â†’ â”‚ qa_generation()     â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                              â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ ã‚¿ã‚¹ã‚¯æŠ•å…¥
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Redis                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼                              â”‚   â”‚
â”‚  â”‚  [Task1] [Task2] [Task3] [Task4] ... [TaskN]                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    çµæœãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰                          â”‚   â”‚
â”‚  â”‚  celery-task-meta-{task_id}: {status, result}               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                   â”‚                   â”‚
           â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker 1      â”‚ â”‚   Worker 2      â”‚ â”‚   Worker N      â”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ OpenAI API  â”‚ â”‚ â”‚ â”‚ OpenAI API  â”‚ â”‚ â”‚ â”‚ OpenAI API  â”‚ â”‚
â”‚ â”‚ å‘¼ã³å‡ºã—    â”‚ â”‚ â”‚ â”‚ å‘¼ã³å‡ºã—    â”‚ â”‚ â”‚ â”‚ å‘¼ã³å‡ºã—    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ çµæœã‚’Redisã«ä¿å­˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ collect_results()   â”‚ â”€â”€â†’ â”‚ çµæœçµ±åˆ    â”‚                       â”‚
â”‚  â”‚ (Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹) â”‚     â”‚ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 ä¸¦åˆ—åŒ–ã•ã‚Œã‚‹å…·ä½“çš„ãªå‡¦ç†

#### ã€ä¸¦åˆ—å¯¾è±¡1ã€‘ãƒãƒ£ãƒ³ã‚¯å˜ä½ã®Q/Aç”Ÿæˆ

```python
@app.task(bind=True, max_retries=3)
def generate_qa_for_chunk_async(self, chunk_data: Dict, config: Dict, model: str) -> Dict:
    """
    å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰Q/Aãƒšã‚¢ã‚’éåŒæœŸç”Ÿæˆ

    å‡¦ç†å†…å®¹:
    1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆè¨€èªåˆ¥ï¼‰
    2. OpenAI APIå‘¼ã³å‡ºã—ï¼ˆclient.responses.parseï¼‰
    3. ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
    4. Q/Aãƒšã‚¢è¿”å´
    """
```

**å®Ÿè£…ç®‡æ‰€**: `celery_tasks.py:193-411`

<details>
<summary>ğŸ“ generate_qa_for_chunk_async() å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
@app.task(bind=True, max_retries=3)
def generate_qa_for_chunk_async(self, chunk_data: Dict, config: Dict, model: str = "gpt-4o-mini") -> Dict:
    """
    å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰Q/Aãƒšã‚¢ã‚’éåŒæœŸç”Ÿæˆï¼ˆCeleryã‚¿ã‚¹ã‚¯ï¼‰

    Args:
        chunk_data: ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿
        config: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«

    Returns:
        ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢ã¨é–¢é€£æƒ…å ±ã‚’å«ã‚€è¾æ›¸
    """
    try:
        logger.info(f"ã‚¿ã‚¹ã‚¯é–‹å§‹: ãƒãƒ£ãƒ³ã‚¯ {chunk_data.get('id', 'unknown')}, ãƒ¢ãƒ‡ãƒ«: {model}")

        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = OpenAI()

        # Q/Aæ•°ã®æ±ºå®š
        num_pairs = determine_qa_count(chunk_data, config)
        lang = config["lang"]

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šï¼ˆè¨€èªåˆ¥ï¼‰
        if lang == "ja":
            system_prompt = """ã‚ãªãŸã¯æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€å­¦ç¿’åŠ¹æœã®é«˜ã„Q&Aãƒšã‚¢ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ç”Ÿæˆãƒ«ãƒ¼ãƒ«:
1. è³ªå•ã¯æ˜ç¢ºã§å…·ä½“çš„ã«
2. å›ç­”ã¯ç°¡æ½”ã§æ­£ç¢ºã«ï¼ˆ1-2æ–‡ç¨‹åº¦ï¼‰
3. ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã«å¿ å®Ÿã«
4. å¤šæ§˜ãªè¦³ç‚¹ã‹ã‚‰è³ªå•ã‚’ä½œæˆ"""

            user_prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰{num_pairs}å€‹ã®Q&Aãƒšã‚¢ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{chunk_data['text']}

JSONå½¢å¼ã§å‡ºåŠ›:
{{
  "qa_pairs": [
    {{
      "question": "è³ªå•æ–‡",
      "answer": "å›ç­”æ–‡",
      "question_type": "fact/reason/comparison/application"
    }}
  ]
}}"""
        else:
            # è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆçœç•¥ï¼‰
            ...

        # OpenAI APIå‘¼ã³å‡ºã—ï¼ˆæ§‹é€ åŒ–å‡ºåŠ›API - Structured Outputsï¼‰
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆ
        combined_input = f"{system_prompt}\n\n{user_prompt}"

        # æœ€æ–°ã®responses.parse APIã‚’ä½¿ç”¨
        response = client.responses.parse(
            input=combined_input,
            model=model,
            text_format=QAPairsResponse,  # Pydanticãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥æŒ‡å®š
            max_output_tokens=2000
        )

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        parsed_response = _extract_parsed_response(response, model)

        # Q/Aãƒšã‚¢ã‚’æŠ½å‡º
        qa_pairs = []
        for qa_data in parsed_response.qa_pairs:
            qa = {
                "question": qa_data.question,
                "answer": qa_data.answer,
                "question_type": qa_data.question_type,
                "source_chunk_id": chunk_data.get('id', ''),
                "doc_id": chunk_data.get('doc_id', ''),
                "dataset_type": chunk_data.get('dataset_type', ''),
                "chunk_idx": chunk_data.get('chunk_idx', 0)
            }
            qa_pairs.append(qa)

        return {
            "success": True,
            "chunk_id": chunk_data.get('id'),
            "qa_pairs": qa_pairs,
            "error": None
        }

    except Exception as e:
        # ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
        if self.request.retries < self.max_retries:
            raise self.retry(exc=e, countdown=5 * (self.request.retries + 1))

        return {
            "success": False,
            "chunk_id": chunk_data.get('id'),
            "qa_pairs": [],
            "error": str(e)
        }
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- `@app.task(bind=True, max_retries=3)`: Celeryã‚¿ã‚¹ã‚¯ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã€‚selfãƒã‚¤ãƒ³ãƒ‰ã¨ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’æŒ‡å®š
- `client.responses.parse()`: æ§‹é€ åŒ–å‡ºåŠ›APIï¼ˆStructured Outputsï¼‰ã‚’ä½¿ç”¨
- `text_format=QAPairsResponse`: Pydanticãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥æŒ‡å®šã—ã¦å‹å®‰å…¨ãªå‡ºåŠ›ã‚’å–å¾—
- è¨€èªåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: `config["lang"]`ã«åŸºã¥ã„ã¦æ—¥æœ¬èª/è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ‡ã‚Šæ›¿ãˆ
- ãƒªãƒˆãƒ©ã‚¤å‡¦ç†: æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ5ç§’ â†’ 10ç§’ â†’ 15ç§’ï¼‰ã§è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

</details>

#### ã€ä¸¦åˆ—å¯¾è±¡2ã€‘ãƒãƒƒãƒå˜ä½ã®Q/Aç”Ÿæˆ

```python
@app.task(bind=True, max_retries=3)
def generate_qa_for_batch_async(self, chunks: List[Dict], config: Dict, model: str) -> Dict:
    """
    è¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ï¼ˆ1-5å€‹ï¼‰ã‹ã‚‰Q/Aãƒšã‚¢ã‚’éåŒæœŸãƒãƒƒãƒç”Ÿæˆ

    åˆ©ç‚¹:
    - APIå‘¼ã³å‡ºã—å›æ•°ã‚’å‰Šæ¸›ï¼ˆæœ€å¤§1/5ï¼‰
    - æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸQ/Aç”ŸæˆãŒå¯èƒ½
    """
```

**å®Ÿè£…ç®‡æ‰€**: `celery_tasks.py:414-646`

#### ã€é€æ¬¡å‡¦ç†ã€‘ã‚¿ã‚¹ã‚¯æŠ•å…¥ãƒ»çµæœåé›†

```python
def submit_parallel_qa_generation(chunks, config, model, batch_size):
    """
    ä¸¦åˆ—Q/Aç”Ÿæˆã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥ï¼ˆé€æ¬¡å‡¦ç†ï¼‰

    å‡¦ç†å†…å®¹:
    1. ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒã«åˆ†å‰²
    2. å„ãƒãƒƒãƒã‚’Celeryã‚¿ã‚¹ã‚¯ã¨ã—ã¦æŠ•å…¥
    3. ã‚¿ã‚¹ã‚¯IDã®ãƒªã‚¹ãƒˆã‚’è¿”å´
    """

def collect_results(tasks, timeout):
    """
    ä¸¦åˆ—å‡¦ç†ã®çµæœã‚’åé›†ï¼ˆé€æ¬¡å‡¦ç†ï¼‰

    å‡¦ç†å†…å®¹:
    1. Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§çµæœå–å¾—
    2. ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ã®ç›£è¦–
    3. Q/Aãƒšã‚¢ã®çµ±åˆ
    """
```

**å®Ÿè£…ç®‡æ‰€**: `celery_tasks.py:649-920`

#### ä¸¦åˆ—å‡¦ç†ã®æµã‚Œå›³

```
ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ã€‘

[å…¥åŠ›: 1000ãƒãƒ£ãƒ³ã‚¯]
         â”‚
         â–¼
[ã‚¿ã‚¹ã‚¯æŠ•å…¥ï¼ˆé€æ¬¡ï¼‰]  â†â”€â”€ submit_parallel_qa_generation()
         â”‚
         â”‚  ãƒãƒƒãƒã‚µã‚¤ã‚º=3ã®å ´åˆ
         â”‚  1000 Ã· 3 = 334ã‚¿ã‚¹ã‚¯
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ã€ä¸¦åˆ—å‡¦ç†ã‚¾ãƒ¼ãƒ³ã€‘                        â”‚
â”‚                                                             â”‚
â”‚   Worker 1         Worker 2         ...      Worker 24     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Task 1   â”‚    â”‚ Task 2   â”‚             â”‚ Task 24  â”‚    â”‚
â”‚   â”‚ Task 25  â”‚    â”‚ Task 26  â”‚             â”‚ Task 48  â”‚    â”‚
â”‚   â”‚ Task 49  â”‚    â”‚ Task 50  â”‚             â”‚ Task 72  â”‚    â”‚
â”‚   â”‚ ...      â”‚    â”‚ ...      â”‚             â”‚ ...      â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”‚   â€» å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒç‹¬ç«‹ã—ã¦OpenAI APIã‚’å‘¼ã³å‡ºã—               â”‚
â”‚   â€» çµæœã¯Redisã«ä¿å­˜                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
[çµæœåé›†ï¼ˆé€æ¬¡ï¼‰]  â†â”€â”€ collect_results()
         â”‚
         â”‚  Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ç¢ºå®Ÿã«çµæœå–å¾—
         â”‚  ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ç›£è¦–ï¼ˆSUCCESS/FAILURE/PENDINGï¼‰
         â”‚
         â–¼
[å‡ºåŠ›: Q/Aãƒšã‚¢ãƒªã‚¹ãƒˆ]
```

### 4.3 ã‚¿ã‚¹ã‚¯è¨­è¨ˆè©³ç´°

#### ã‚¿ã‚¹ã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | èª¬æ˜ |
|-----------|-----|------|
| chunk_data / chunks | Dict / List[Dict] | ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ |
| config | Dict | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šï¼ˆlang, qa_per_chunkç­‰ï¼‰ |
| model | str | OpenAIãƒ¢ãƒ‡ãƒ«å |

#### ã‚¿ã‚¹ã‚¯æˆ»ã‚Šå€¤

```python
{
    "success": True,                    # æˆåŠŸãƒ•ãƒ©ã‚°
    "chunk_id": "cc_news_0_chunk_1",    # ãƒãƒ£ãƒ³ã‚¯IDï¼ˆå˜ä¸€å‡¦ç†æ™‚ï¼‰
    "chunk_ids": ["...", "..."],        # ãƒãƒ£ãƒ³ã‚¯IDãƒªã‚¹ãƒˆï¼ˆãƒãƒƒãƒå‡¦ç†æ™‚ï¼‰
    "qa_pairs": [                       # ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢
        {
            "question": "è³ªå•æ–‡",
            "answer": "å›ç­”æ–‡",
            "question_type": "fact",
            "source_chunk_id": "...",
            "doc_id": "...",
            "dataset_type": "cc_news",
            "chunk_idx": 0
        }
    ],
    "error": None                       # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå¤±æ•—æ™‚ï¼‰
}
```

### 4.4 ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### Celeryè¨­å®šï¼ˆconfig.pyï¼‰

```python
class CeleryConfig:
    BROKER_URL = "redis://localhost:6379/0"
    RESULT_BACKEND = "redis://localhost:6379/0"
    TASK_SERIALIZER = "json"
    RESULT_SERIALIZER = "json"
    ACCEPT_CONTENT = ["json"]
    TIMEZONE = "Asia/Tokyo"
    ENABLE_UTC = True
    TASK_TIME_LIMIT = 300        # 5åˆ†
    TASK_SOFT_TIME_LIMIT = 240   # 4åˆ†
    WORKER_CONCURRENCY = 4       # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    WORKER_PREFETCH_MULTIPLIER = 1
```

#### ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®æ±ºå®šåŸºæº–

| è¦å›  | æ¨å¥¨ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° |
|------|---------------|
| OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ | Tierä¾å­˜ï¼ˆTPM/RPMï¼‰ |
| CPU/ãƒ¡ãƒ¢ãƒª | ç‰©ç†ã‚³ã‚¢æ•° Ã— 2ç¨‹åº¦ |
| å‡¦ç†ãƒ‡ãƒ¼ã‚¿é‡ | å¤§é‡ â†’ å¤šãƒ¯ãƒ¼ã‚«ãƒ¼ |
| å®‰å®šæ€§é‡è¦– | å°‘ãªã‚ï¼ˆ8-16ï¼‰ |
| é€Ÿåº¦é‡è¦– | å¤šã‚ï¼ˆ24-48ï¼‰ |

#### ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ï¼ˆ24ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰
./start_celery.sh start -w 24

# ãƒ¯ãƒ¼ã‚«ãƒ¼å†èµ·å‹•ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å«ã‚€ï¼‰
redis-cli FLUSHDB && ./start_celery.sh restart -w 24

# ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ç¢ºèª
./start_celery.sh status

# ãƒ¯ãƒ¼ã‚«ãƒ¼åœæ­¢
./start_celery.sh stop
```

### 4.5 çµæœåé›†ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆRedisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ï¼‰

#### ãªãœRedisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã‹

Celeryã® `task.get()` ã§ã¯ã€ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ãŒ `PENDING` ã¨èª¤èªè­˜ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚
Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã«ã‚ˆã‚Šã€ç¢ºå®Ÿã«çµæœã‚’å–å¾—ã§ãã‚‹ã€‚

#### çµæœåé›†ã®æµã‚Œ

```python
def collect_results(tasks, timeout):
    redis_client = redis.Redis(...)

    while not all_completed:
        for task in tasks:
            # 1. Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
            redis_key = f"celery-task-meta-{task.id}"
            redis_data = redis_client.get(redis_key)

            if redis_data:
                result = json.loads(redis_data)
                if result['status'] == 'SUCCESS':
                    # çµæœã‚’å–å¾—
                    qa_pairs.extend(result['result']['qa_pairs'])

            # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Celery API
            if task.state == 'SUCCESS':
                result = task.get(timeout=1)
                # ...
```

**å®Ÿè£…ç®‡æ‰€**: `celery_tasks.py:688-920`

<details>
<summary>ğŸ“ submit_parallel_qa_generation() / collect_results() å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
def submit_parallel_qa_generation(chunks: List[Dict], config: Dict, model: str = "gpt-4o-mini",
                                 batch_size: int = 3) -> List:
    """
    ä¸¦åˆ—Q/Aç”Ÿæˆã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥

    Args:
        chunks: ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
        config: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆ1-5ï¼‰

    Returns:
        Celeryã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    tasks = []

    # ãƒãƒƒãƒå‡¦ç†ã®å ´åˆ
    if batch_size > 1:
        for i in range(0, len(chunks), batch_size):
            batch = chunks[i:i+batch_size]
            task = generate_qa_for_batch_async.apply_async(
                args=[batch, config, model],
                queue='qa_generation'  # ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒç›£è¦–ã—ã¦ã„ã‚‹ã‚­ãƒ¥ãƒ¼ã‚’æŒ‡å®š
            )
            tasks.append(task)
            logger.debug(f"ã‚¿ã‚¹ã‚¯æŠ•å…¥: {task.id} - {len(batch)}ãƒãƒ£ãƒ³ã‚¯")
    else:
        # å€‹åˆ¥å‡¦ç†ã®å ´åˆ
        for chunk in chunks:
            task = generate_qa_for_chunk_async.apply_async(
                args=[chunk, config, model],
                queue='qa_generation'
            )
            tasks.append(task)

    logger.info(f"æŠ•å…¥ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯æ•°: {len(tasks)}")
    return tasks


def collect_results(tasks: List, timeout: int = 300) -> List[Dict]:
    """
    ä¸¦åˆ—å‡¦ç†ã®çµæœã‚’åé›†ï¼ˆæ”¹è‰¯ç‰ˆï¼šRedisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ç¢ºå®Ÿãªçµæœå–å¾—ï¼‰

    Args:
        tasks: Celeryã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
        timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

    Returns:
        Q/Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
    """
    import time
    import redis
    import json
    from celery.result import AsyncResult

    all_qa_pairs = []
    failed_chunks = []
    total_tasks = len(tasks)
    completed_tasks = set()
    failed_tasks = set()

    # Redisæ¥ç¶šã‚’ç¢ºç«‹
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        db=int(os.getenv('REDIS_DB', 0)),
        decode_responses=True
    )

    start_time = time.time()

    while len(completed_tasks) + len(failed_tasks) < total_tasks:
        current_time = time.time()
        elapsed = current_time - start_time

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
        if elapsed > timeout:
            logger.error(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {elapsed:.1f}ç§’çµŒé")
            break

        # å„ã‚¿ã‚¹ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
        for i, task in enumerate(tasks):
            if i in completed_tasks or i in failed_tasks:
                continue

            try:
                # Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆæœ€ã‚‚ç¢ºå®Ÿãªæ–¹æ³•ï¼‰
                redis_key = f"celery-task-meta-{task.id}"
                redis_data = redis_client.get(redis_key)

                if redis_data:
                    redis_result = json.loads(redis_data)
                    redis_state = redis_result.get('status')

                    # Redisã§æˆåŠŸã—ã¦ã„ã‚‹å ´åˆ
                    if redis_state == 'SUCCESS':
                        result = redis_result.get('result')
                        if result and isinstance(result, dict) and result.get('success'):
                            qa_pairs = result.get('qa_pairs', [])
                            all_qa_pairs.extend(qa_pairs)
                            completed_tasks.add(i)
                            logger.info(f"âœ“ ã‚¿ã‚¹ã‚¯ {i+1}/{total_tasks} å®Œäº†: {len(qa_pairs)}å€‹ã®Q/A")
                        elif result is not None:
                            failed_tasks.add(i)

                    elif redis_state == 'FAILURE':
                        failed_tasks.add(i)

            except Exception as e:
                logger.debug(f"ã‚¿ã‚¹ã‚¯ {i+1} ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")

        time.sleep(0.5)

    # çµæœã‚µãƒãƒªãƒ¼
    elapsed_total = time.time() - start_time
    logger.info(f"""
    çµæœåé›†å®Œäº†:
    - æˆåŠŸ: {len(completed_tasks)}/{total_tasks}ã‚¿ã‚¹ã‚¯
    - å¤±æ•—: {len(failed_tasks)}ã‚¿ã‚¹ã‚¯
    - ç”ŸæˆQ/Aãƒšã‚¢: {len(all_qa_pairs)}å€‹
    - æ‰€è¦æ™‚é–“: {elapsed_total:.1f}ç§’
    """)

    return all_qa_pairs
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- `apply_async(queue='qa_generation')`: æŒ‡å®šã‚­ãƒ¥ãƒ¼ã¸ã®ã‚¿ã‚¹ã‚¯æŠ•å…¥
- `redis.Redis()`: Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ç¢ºå®Ÿãªçµæœå–å¾—
- `celery-task-meta-{task_id}`: Celeryã®çµæœä¿å­˜ã‚­ãƒ¼å½¢å¼
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–: æŒ‡å®šæ™‚é–“å†…ã«å®Œäº†ã—ãªã„å ´åˆã¯ä¸­æ–­
- åœæ»æ¤œçŸ¥: 30ç§’ã”ã¨ã«é€²æ—ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€3åˆ†é–“é€²æ—ãŒãªã„å ´åˆã¯çŠ¶æ…‹ã‚’å¼·åˆ¶ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥

</details>

### 4.6 ãƒªãƒˆãƒ©ã‚¤ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### ãƒªãƒˆãƒ©ã‚¤è¨­å®š

```python
@app.task(bind=True, max_retries=3)
def generate_qa_for_chunk_async(self, ...):
    try:
        # å‡¦ç†
    except Exception as e:
        if self.request.retries < self.max_retries:
            # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
            raise self.retry(exc=e, countdown=5 * (self.request.retries + 1))
        return {"success": False, "error": str(e)}
```

| ãƒªãƒˆãƒ©ã‚¤å›æ•° | å¾…æ©Ÿæ™‚é–“ |
|-------------|---------|
| 1å›ç›® | 5ç§’ |
| 2å›ç›® | 10ç§’ |
| 3å›ç›® | 15ç§’ |

#### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

| ã‚¨ãƒ©ãƒ¼ç¨®é¡ | å¯¾å‡¦ |
|-----------|------|
| APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ | ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§3å›ï¼‰ |
| JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç† |
| ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | æ¬¡ã‚¿ã‚¹ã‚¯ã¸ç¶™ç¶š |
| ãƒ¯ãƒ¼ã‚«ãƒ¼éšœå®³ | ã‚¿ã‚¹ã‚¯å†ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚° |

---

## 5. å‡ºåŠ›ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜

### 5.1 å‡ºåŠ›å½¢å¼

#### JSONå½¢å¼

```json
[
  {
    "question": "OpenAIã®GPT-4oã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "answer": "GPT-4oã¯ã€OpenAIãŒé–‹ç™ºã—ãŸæœ€æ–°ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚",
    "question_type": "fact",
    "source_chunk_id": "cc_news_0_chunk_1",
    "doc_id": "cc_news_0_AIã®é€²åŒ–",
    "dataset_type": "cc_news",
    "chunk_idx": 1
  }
]
```

#### CSVå½¢å¼

| question | answer | question_type | source_chunk_id | doc_id | dataset_type | chunk_idx |
|----------|--------|---------------|-----------------|--------|--------------|-----------|
| OpenAIã®GPT-4oã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ | GPT-4oã¯... | fact | cc_news_0_chunk_1 | cc_news_0_AIã®é€²åŒ– | cc_news | 1 |

### 5.2 ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡

| ãƒ•ã‚¡ã‚¤ãƒ«ç¨®é¡ | å‘½åè¦å‰‡ | ä¾‹ |
|-------------|---------|-----|
| Q/A JSON | `qa_pairs_{dataset}_{timestamp}.json` | `qa_pairs_cc_news_20251128_143052.json` |
| Q/A CSV | `qa_pairs_{dataset}_{timestamp}.csv` | `qa_pairs_cc_news_20251128_143052.csv` |
| çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | `a02_qa_pairs_{dataset}.csv` | `a02_qa_pairs_cc_news.csv` |
| ã‚«ãƒãƒ¬ãƒ¼ã‚¸ | `coverage_{dataset}_{timestamp}.json` | `coverage_cc_news_20251128_143052.json` |
| ã‚µãƒãƒªãƒ¼ | `summary_{dataset}_{timestamp}.json` | `summary_cc_news_20251128_143052.json` |

### 5.3 ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸

å„Q/Aãƒšã‚¢ã«ã¯ä»¥ä¸‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè‡ªå‹•ä»˜ä¸ã•ã‚Œã‚‹ï¼š

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | èª¬æ˜ |
|-----------|------|
| source_chunk_id | å…ƒãƒãƒ£ãƒ³ã‚¯ã®ID |
| doc_id | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID |
| dataset_type | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ— |
| chunk_idx | ãƒãƒ£ãƒ³ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ |
| question_type | è³ªå•ã‚¿ã‚¤ãƒ—ï¼ˆfact/reason/comparison/applicationï¼‰ |

### 5.4 ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
qa_output/
â”œâ”€â”€ a02/                              # a02_make_qa_para.py ã®å‡ºåŠ›
â”‚   â”œâ”€â”€ qa_pairs_cc_news_20251128_143052.json
â”‚   â”œâ”€â”€ qa_pairs_cc_news_20251128_143052.csv
â”‚   â”œâ”€â”€ coverage_cc_news_20251128_143052.json
â”‚   â””â”€â”€ summary_cc_news_20251128_143052.json
â”‚
â””â”€â”€ a02_qa_pairs_cc_news.csv          # çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆquestion, answerã®ã¿ï¼‰
```

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:1776-1859`

---

## 6. ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ

### 6.1 ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã®æ¦‚å¿µã¨ç›®çš„

**ã‚«ãƒãƒ¬ãƒ¼ã‚¸**ã¨ã¯ã€ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢ãŒå…ƒã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã©ã®ç¨‹åº¦ç¶²ç¾…ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã™æŒ‡æ¨™ã€‚

```
ã€ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã®è€ƒãˆæ–¹ã€‘

ãƒãƒ£ãƒ³ã‚¯åŸ‹ã‚è¾¼ã¿ç©ºé–“:
    â—‹ ãƒãƒ£ãƒ³ã‚¯1 â”€â”€â”€â”€â”
    â—‹ ãƒãƒ£ãƒ³ã‚¯2 â”€â”€â”€â”€â”¼â”€â”€ Q/A1 ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    â—‹ ãƒãƒ£ãƒ³ã‚¯3 â”€â”€â”€â”€â”˜

    é¡ä¼¼åº¦ >= é–¾å€¤ â†’ ã‚«ãƒãƒ¼æ¸ˆã¿
    é¡ä¼¼åº¦ <  é–¾å€¤ â†’ æœªã‚«ãƒãƒ¼

ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡ = ã‚«ãƒãƒ¼æ¸ˆã¿ãƒãƒ£ãƒ³ã‚¯æ•° / ç·ãƒãƒ£ãƒ³ã‚¯æ•°
```

### 6.2 è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def analyze_coverage(chunks, qa_pairs, threshold):
    # 1. åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    doc_embeddings = generate_embeddings(chunks)
    qa_embeddings = generate_embeddings(qa_pairs)

    # 2. ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¡Œåˆ—è¨ˆç®—
    coverage_matrix = np.zeros((len(chunks), len(qa_pairs)))
    for i in range(len(doc_embeddings)):
        for j in range(len(qa_embeddings)):
            similarity = cosine_similarity(doc_embeddings[i], qa_embeddings[j])
            coverage_matrix[i, j] = similarity

    # 3. æœ€å¤§é¡ä¼¼åº¦ã§ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ¤å®š
    max_similarities = coverage_matrix.max(axis=1)
    covered_count = sum(1 for s in max_similarities if s >= threshold)
    coverage_rate = covered_count / len(chunks)

    return coverage_rate
```

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:1647-1769`

<details>
<summary>ğŸ“ analyze_coverage() å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
def analyze_coverage(chunks: List[Dict], qa_pairs: List[Dict], dataset_type: str = "wikipedia_ja",
                     custom_threshold: Optional[float] = None) -> Dict:
    """ç”Ÿæˆã•ã‚ŒãŸQ/Aãƒšã‚¢ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ã‚’åˆ†æï¼ˆå¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æå¯¾å¿œï¼‰

    Args:
        chunks: ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆ
        qa_pairs: Q/Aãƒšã‚¢ãƒªã‚¹ãƒˆ
        dataset_type: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ—ï¼ˆé–¾å€¤è‡ªå‹•è¨­å®šã«ä½¿ç”¨ï¼‰
        custom_threshold: ã‚«ã‚¹ã‚¿ãƒ é–¾å€¤ï¼ˆæŒ‡å®šæ™‚ã¯ã“ã‚Œã‚’ä½¿ç”¨ï¼‰

    Returns:
        ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æçµæœï¼ˆå¤šæ®µéšè©•ä¾¡ã€ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ†æã‚’å«ã‚€ï¼‰
    """
    analyzer = SemanticCoverage()

    # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆãƒãƒƒãƒAPIæœ€é©åŒ–ç‰ˆï¼‰
    logger.info("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆä¸­...")

    # ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    doc_embeddings = analyzer.generate_embeddings(chunks)

    # Q&Aãƒšã‚¢ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆãƒãƒƒãƒAPIä½¿ç”¨ã§é«˜é€ŸåŒ–ï¼‰
    qa_texts = [f"{qa['question']} {qa['answer']}" for qa in qa_pairs]
    qa_embeddings = analyzer.generate_embeddings_batch(qa_texts, batch_size=2048)

    if len(qa_embeddings) == 0:
        return {
            "coverage_rate": 0.0,
            "covered_chunks": 0,
            "total_chunks": len(chunks),
            "uncovered_chunks": chunks,
            "multi_threshold": {},
            "chunk_analysis": {}
        }

    # ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¡Œåˆ—è¨ˆç®—
    logger.info("ã‚«ãƒãƒ¬ãƒ¼ã‚¸è¡Œåˆ—è¨ˆç®—ä¸­...")
    coverage_matrix = np.zeros((len(chunks), len(qa_pairs)))
    for i in range(len(doc_embeddings)):
        for j in range(len(qa_embeddings)):
            similarity = analyzer.cosine_similarity(doc_embeddings[i], qa_embeddings[j])
            coverage_matrix[i, j] = similarity

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥æœ€é©é–¾å€¤ã‚’å–å¾—
    thresholds = get_optimal_thresholds(dataset_type)

    # ã‚«ã‚¹ã‚¿ãƒ é–¾å€¤ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä¸Šæ›¸ã
    if custom_threshold is not None:
        standard_threshold = custom_threshold
    else:
        standard_threshold = thresholds["standard"]

    # åŸºæœ¬ã‚«ãƒãƒ¬ãƒ¼ã‚¸ï¼ˆæ¨™æº–é–¾å€¤ï¼‰
    max_similarities = coverage_matrix.max(axis=1)
    covered_count = sum(1 for s in max_similarities if s >= standard_threshold)
    coverage_rate = covered_count / len(chunks) if chunks else 0

    # æœªã‚«ãƒãƒ¼ãƒãƒ£ãƒ³ã‚¯ã®ç‰¹å®š
    uncovered_chunks = []
    for i, (chunk, sim) in enumerate(zip(chunks, max_similarities)):
        if sim < standard_threshold:
            uncovered_chunks.append({
                'chunk': chunk,
                'similarity': float(sim),
                'gap': float(standard_threshold - sim)
            })

    # å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ
    multi_threshold_results = multi_threshold_coverage(coverage_matrix, chunks, qa_pairs, thresholds)

    # ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æ
    chunk_characteristics = analyze_chunk_characteristics_coverage(
        chunks, coverage_matrix, qa_pairs, standard_threshold
    )

    # çµæœã‚’çµ±åˆ
    results = {
        # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        "coverage_rate": coverage_rate,
        "covered_chunks": covered_count,
        "total_chunks": len(chunks),
        "uncovered_chunks": uncovered_chunks,
        "max_similarities": max_similarities.tolist(),
        "threshold": standard_threshold,

        # å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸
        "multi_threshold": multi_threshold_results,

        # ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æ
        "chunk_analysis": chunk_characteristics,

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
        "dataset_type": dataset_type,
        "optimal_thresholds": thresholds
    }

    return results
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- `SemanticCoverage`: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹
- `generate_embeddings_batch()`: ãƒãƒƒãƒAPIã‚’ä½¿ç”¨ã—ãŸé«˜é€ŸåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
- `get_optimal_thresholds()`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ã®æœ€é©é–¾å€¤ã‚’å–å¾—
- `multi_threshold_coverage()`: strict/standard/lenient ã®3æ®µéšé–¾å€¤ã§åˆ†æ
- `analyze_chunk_characteristics_coverage()`: ãƒãƒ£ãƒ³ã‚¯é•·ã•ãƒ»ä½ç½®ã«ã‚ˆã‚‹ç‰¹æ€§åˆ†æ

</details>

### 6.3 é–¾å€¤è¨­å®šã¨èª¿æ•´

#### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥æœ€é©é–¾å€¤

| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | strict | standard | lenient |
|-------------|--------|----------|---------|
| cc_news | 0.80 | 0.70 | 0.60 |
| japanese_text | 0.75 | 0.65 | 0.55 |
| wikipedia_ja | 0.85 | 0.75 | 0.65 |
| livedoor | 0.78 | 0.68 | 0.58 |

#### é–¾å€¤ã®è€ƒãˆæ–¹

| é–¾å€¤ãƒ¬ãƒ™ãƒ« | ç”¨é€” |
|-----------|------|
| strict | é«˜å“è³ªQ/AãŒå¿…è¦ãªå ´åˆ |
| standard | ä¸€èˆ¬çš„ãªç”¨é€”ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ |
| lenient | ã‚«ãƒãƒ¬ãƒ¼ã‚¸ç‡ã‚’å„ªå…ˆã™ã‚‹å ´åˆ |

**å®Ÿè£…ç®‡æ‰€**: `a02_make_qa_para.py:1467-1502`

### 6.4 åˆ†æçµæœã®è§£é‡ˆ

#### å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ

```
å¤šæ®µéšã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æçµæœ:
- Strict  (é–¾å€¤0.80): 72.5%
- Standard(é–¾å€¤0.70): 85.3%
- Lenient (é–¾å€¤0.60): 94.1%
```

#### ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥åˆ†æ

```
ãƒãƒ£ãƒ³ã‚¯ç‰¹æ€§åˆ¥ã‚«ãƒãƒ¬ãƒ¼ã‚¸:
é•·ã•åˆ¥:
- Short ãƒãƒ£ãƒ³ã‚¯: 68.5%   â† çŸ­ã„ãƒãƒ£ãƒ³ã‚¯ã¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„å‚¾å‘
- Medium ãƒãƒ£ãƒ³ã‚¯: 88.2%
- Long ãƒãƒ£ãƒ³ã‚¯: 92.1%

ä½ç½®åˆ¥:
- Beginning (å‰åŠ): 90.5%
- Middle (ä¸­ç›¤): 87.3%
- End (å¾ŒåŠ): 78.9%   â† æ–‡æ›¸å¾ŒåŠã¯ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„å‚¾å‘
```

#### ã‚¤ãƒ³ã‚µã‚¤ãƒˆ

```
ğŸ“Š åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆ:
â€¢ shortãƒãƒ£ãƒ³ã‚¯ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„ï¼ˆ68.5%ï¼‰
â€¢ æ–‡æ›¸endéƒ¨åˆ†ã®ã‚«ãƒãƒ¬ãƒ¼ã‚¸ãŒä½ã„ï¼ˆ78.9%ï¼‰
```

---

## 7. UIã‹ã‚‰ã®å®Ÿè¡Œï¼ˆStreamlitï¼‰

### 7.1 qa_generation_page.pyã®æ§‹é€ 

```python
def show_qa_generation_page():
    """ç”»é¢2: Q/Aç”Ÿæˆ"""

    # 1. æœ€æ–°ã®Q/Aå±¥æ­´è¡¨ç¤º
    df_history = load_qa_output_history()
    st.dataframe(df_history)

    # 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼: å…¥åŠ›ã‚½ãƒ¼ã‚¹é¸æŠ
    with st.sidebar:
        input_source = st.radio("å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ", ["dataset", "local_file"])

        # 3. Q/Aç”Ÿæˆè¨­å®š
        use_celery = st.checkbox("Celeryä¸¦åˆ—å‡¦ç†", value=True)
        celery_workers = st.number_input("Celeryãƒ¯ãƒ¼ã‚«ãƒ¼æ•°", value=24)
        # ...

    # 4. å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("Q/Aç”Ÿæˆé–‹å§‹"):
        result = run_advanced_qa_generation(...)
```

**å®Ÿè£…ç®‡æ‰€**: `ui/pages/qa_generation_page.py:25-365`

<details>
<summary>ğŸ“ run_advanced_qa_generation() / _extract_parsed_response() å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

**1. UIã‹ã‚‰ã®ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œï¼ˆrun_advanced_qa_generationï¼‰**

```python
def run_advanced_qa_generation(
    dataset: Optional[str],
    input_file: Optional[str],
    use_celery: bool,
    celery_workers: int,
    batch_chunks: int,
    max_docs: int,
    merge_chunks: bool,
    min_tokens: int,
    max_tokens: int,
    coverage_threshold: float,
    model: str,
    analyze_coverage: bool,
    log_callback,
    progress_callback=None,
) -> Dict[str, Any]:
    """
    a02_make_qa_para.pyã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ

    æ”¹å–„å†…å®¹:
    - Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã«ã‚ˆã‚‹ç¢ºå®Ÿãªçµæœåé›†
    - ã‚¿ã‚¹ã‚¯çŠ¶æ…‹èª¤èªè­˜ï¼ˆPENDINGï¼‰ã®å›é¿
    - ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†æ™‚ã®Celeryæ¥ç¶šã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    """
    # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
    cmd = [sys.executable, "a02_make_qa_para.py"]

    if dataset:
        cmd.extend(["--dataset", dataset])
    elif input_file:
        cmd.extend(["--input-file", input_file])

    if use_celery:
        cmd.append("--use-celery")
        cmd.extend(["--celery-workers", str(celery_workers)])

    cmd.extend([
        "--batch-chunks", str(batch_chunks),
        "--max-docs", str(max_docs),
        "--min-tokens", str(min_tokens),
        "--max-tokens", str(max_tokens),
        "--coverage-threshold", str(coverage_threshold),
        "--model", model,
    ])

    if merge_chunks:
        cmd.append("--merge-chunks")
    if analyze_coverage:
        cmd.append("--analyze-coverage")

    log_callback(f"ğŸš€ é«˜åº¦ãªQ/Aç”Ÿæˆã‚’é–‹å§‹: {' '.join(cmd)}")

    # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        universal_newlines=True,
        bufsize=1,
        env=os.environ.copy(),
    )

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ­ã‚°ã‚’å‡¦ç†
    saved_files = None
    qa_count = 0
    coverage_results = None

    # å‡ºåŠ›ã‚’èª­ã¿å–ã‚ŠãªãŒã‚‰é€²æ—ã‚’æ›´æ–°
    for line in iter(process.stdout.readline, ""):
        log_callback(line.strip())

        # é€²æ—æƒ…å ±ã‚’æŠ½å‡º
        if progress_callback:
            progress_match = re.search(r"é€²æ—.*?å®Œäº†[=:ï¼š\s]*(\d+)\s*/\s*(\d+)", line)
            if progress_match:
                current = int(progress_match.group(1))
                total = int(progress_match.group(2))
                progress_callback(current, total)

        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŠ½å‡º
        if "CSVä¿å­˜:" in line:
            csv_match = line.split("CSVä¿å­˜:")[-1].strip()
            saved_files = {"csv": f"qa_output/{csv_match}"}

    process.wait()

    if process.returncode == 0:
        return {
            "success": True,
            "saved_files": saved_files,
            "qa_count": qa_count,
            "coverage_results": coverage_results,
        }
    else:
        return {"success": False, "return_code": process.returncode}
```

**2. ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æï¼ˆ_extract_parsed_responseï¼‰**

```python
def _extract_parsed_response(response, model: str) -> QAPairsResponse:
    """
    responses.parse() API ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

    Args:
        response: OpenAI API ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        model: ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«å

    Returns:
        QAPairsResponse ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    parsed_response = None

    # æ–¹æ³•1: output_parsedå±æ€§ã‚’ç›´æ¥ç¢ºèªï¼ˆGPT-5ã‚·ãƒªãƒ¼ã‚ºå¯¾å¿œï¼‰
    if hasattr(response, 'output_parsed') and response.output_parsed:
        parsed_response = response.output_parsed
        logger.info("GPT-5å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆoutput_parsedï¼‰ã‚’ä½¿ç”¨")
        return parsed_response

    # æ–¹æ³•2: outputé…åˆ—ã‹ã‚‰æ¢ç´¢ï¼ˆGPT-4oå¯¾å¿œï¼‰
    if hasattr(response, 'output'):
        for output in response.output:
            if hasattr(output, 'type'):
                if output.type == "reasoning":
                    continue  # ReasoningItemã¯ã‚¹ã‚­ãƒƒãƒ—
                elif output.type == "message" and hasattr(output, 'content'):
                    for item in output.content:
                        if hasattr(item, 'type') and item.type == "output_text":
                            if hasattr(item, 'parsed') and item.parsed:
                                return item.parsed

    # æ–¹æ³•3: textå±æ€§ã‹ã‚‰JSONç›´æ¥è§£æ
    if hasattr(response, 'output'):
        for output in response.output:
            if hasattr(output, 'type') and output.type == "message":
                for item in output.content:
                    if hasattr(item, 'text') and item.text:
                        try:
                            json_data = json.loads(item.text)
                            if 'qa_pairs' in json_data:
                                return QAPairsResponse(**json_data)
                        except json.JSONDecodeError:
                            pass

    # æ–¹æ³•4: output_textå±æ€§ã‹ã‚‰ç›´æ¥è§£æ
    if hasattr(response, 'output_text') and response.output_text:
        try:
            json_data = json.loads(response.output_text)
            if 'qa_pairs' in json_data:
                return QAPairsResponse(**json_data)
        except Exception:
            pass

    if not parsed_response:
        raise ValueError("No parsable response from OpenAI API")

    return parsed_response
```

**ãƒã‚¤ãƒ³ãƒˆ**:
- `subprocess.Popen()`: ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§a02_make_qa_para.pyã‚’å®Ÿè¡Œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°: `iter(process.stdout.readline, "")`ã§1è¡Œãšã¤èª­ã¿å–ã‚Š
- é€²æ—ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ: æ­£è¦è¡¨ç¾ã§ã€Œé€²æ—: å®Œäº†=123/305ã€å½¢å¼ã‚’æ¤œå‡º
- GPT-5/GPT-4oå¯¾å¿œ: `output_parsed`ã¨`output[].content[].parsed`ã®ä¸¡æ–¹ã‚’è©¦è¡Œ
- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: textå±æ€§ã‹ã‚‰JSONç›´æ¥è§£æã‚‚å®Ÿè£…

</details>

### 7.2 å…¥åŠ›ã‚½ãƒ¼ã‚¹é¸æŠ

| ã‚½ãƒ¼ã‚¹ | èª¬æ˜ |
|--------|------|
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | DATASET_CONFIGSã§å®šç¾©ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ |
| ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« | CSV/JSON/JSONL/TXT ãƒ•ã‚¡ã‚¤ãƒ« |

### 7.3 è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | UIè¦ç´  | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
|-----------|--------|-----------|
| Celeryä¸¦åˆ—å‡¦ç† | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ | æœ‰åŠ¹ |
| ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° | æ•°å€¤å…¥åŠ› | 24 |
| ãƒãƒƒãƒãƒãƒ£ãƒ³ã‚¯æ•° | æ•°å€¤å…¥åŠ› | 3 |
| æœ€å¤§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•° | æ•°å€¤å…¥åŠ› | 100 |
| ãƒãƒ£ãƒ³ã‚¯çµ±åˆ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ | æœ‰åŠ¹ |
| ã‚«ãƒãƒ¬ãƒ¼ã‚¸åˆ†æ | ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ | æœ‰åŠ¹ |
| ãƒ¢ãƒ‡ãƒ« | ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ | gpt-4o-mini |

### 7.4 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º

```python
def update_progress(current: int, total: int):
    """é€²æ—ãƒãƒ¼ã‚’æ›´æ–°"""
    progress = current / total
    progress_bar.progress(progress, text=f"é€²æ—: {current}/{total} ã‚¿ã‚¹ã‚¯å®Œäº†")
```

---

## 8. å®Ÿè¡Œä¾‹ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 8.1 å…¸å‹çš„ãªå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

#### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿ï¼‰

```bash
# 1ãƒãƒ£ãƒ³ã‚¯ã§ãƒ†ã‚¹ãƒˆ
python a02_make_qa_para.py \
  --dataset cc_news \
  --max-docs 1 \
  --batch-chunks 1 \
  --model gpt-4o-mini
```

#### æœ¬ç•ªå®Ÿè¡Œï¼ˆCeleryä¸¦åˆ—ï¼‰

```bash
# 1. Celeryãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
redis-cli FLUSHDB && ./start_celery.sh restart -w 24

# 2. Q/Aç”Ÿæˆå®Ÿè¡Œ
python a02_make_qa_para.py \
  --dataset cc_news \
  --use-celery \
  --celery-workers 24 \
  --batch-chunks 3 \
  --merge-chunks \
  --min-tokens 150 \
  --max-tokens 400 \
  --coverage-threshold 0.58 \
  --model gpt-4o-mini \
  --analyze-coverage
```

#### ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å®Ÿè¡Œ

```bash
python a02_make_qa_para.py \
  --input-file qa_output/my_data.csv \
  --use-celery \
  --celery-workers 24 \
  --batch-chunks 3 \
  --max-docs 100 \
  --model gpt-4o-mini \
  --analyze-coverage
```

### 8.2 ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦

| å•é¡Œ | åŸå›  | å¯¾å‡¦ |
|------|------|------|
| ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ãªã„ | RedisãŒèµ·å‹•ã—ã¦ã„ãªã„ | `brew services start redis` |
| ã‚¿ã‚¹ã‚¯ãŒå‡¦ç†ã•ã‚Œãªã„ | ã‚­ãƒ¥ãƒ¼ã«ã‚¿ã‚¹ã‚¯ãŒæºœã¾ã£ã¦ã„ã‚‹ | `redis-cli FLUSHDB` |
| çµæœãŒåé›†ã•ã‚Œãªã„ | ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ã®èª¤èªè­˜ | Redisç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ç¢ºèª |
| APIã‚¨ãƒ©ãƒ¼ | ãƒ¬ãƒ¼ãƒˆåˆ¶é™ | ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’æ¸›ã‚‰ã™ |
| ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | å‡¦ç†æ™‚é–“è¶…é | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’å¢—åŠ  |

#### è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ¯ãƒ¼ã‚«ãƒ¼çŠ¶æ…‹ç¢ºèª
./start_celery.sh status

# Redisã‚­ãƒ¥ãƒ¼ç¢ºèª
redis-cli LLEN celery

# ãƒ­ã‚°ç¢ºèª
tail -f logs/celery_qa_*.log

# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep celery
```

### 8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | æ¨å¥¨å€¤ | å½±éŸ¿ |
|-----------|--------|------|
| --celery-workers | 16-24 | å‡¦ç†é€Ÿåº¦ â†‘ã€APIè² è· â†‘ |
| --batch-chunks | 3 | APIå‘¼ã³å‡ºã—å›æ•° â†“ |
| --merge-chunks | æœ‰åŠ¹ | ãƒãƒ£ãƒ³ã‚¯æ•° â†“ã€å‡¦ç†é€Ÿåº¦ â†‘ |
| --min-tokens | 150 | å°ãƒãƒ£ãƒ³ã‚¯çµ±åˆåŸºæº– |
| --max-tokens | 400 | çµ±åˆå¾Œã®æœ€å¤§ã‚µã‚¤ã‚º |

#### å‡¦ç†æ™‚é–“ã®ç›®å®‰

| ãƒ‡ãƒ¼ã‚¿é‡ | ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° | ãƒãƒƒãƒã‚µã‚¤ã‚º | æ¨å®šæ™‚é–“ |
|---------|-----------|-------------|---------|
| 100ãƒãƒ£ãƒ³ã‚¯ | 8 | 3 | 1-2åˆ† |
| 500ãƒãƒ£ãƒ³ã‚¯ | 16 | 3 | 3-5åˆ† |
| 1000ãƒãƒ£ãƒ³ã‚¯ | 24 | 3 | 5-8åˆ† |
| 5000ãƒãƒ£ãƒ³ã‚¯ | 24 | 5 | 20-30åˆ† |

---

## å‚è€ƒè³‡æ–™

- `doc/01_chunk.md`: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æŠ€è¡“ã®è©³ç´°
- `doc/02_prompt.md`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®è©³ç´°
- `doc/helper_api.md`: OpenAI APIé–¢é€£ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
