# Qdrantçµ±åˆãƒ»æ¤œç´¢ãƒ»ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†

ä½œæˆæ—¥: 2025-11-28

## ç›®æ¬¡

1. [æ¦‚è¦](#1-æ¦‚è¦)
   - 1.1 [æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„](#11-æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„)
   - 1.2 [RAGã«ãŠã‘ã‚‹Qdrantã®å½¹å‰²](#12-ragã«ãŠã‘ã‚‹qdrantã®å½¹å‰²)
   - 1.3 [é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§](#13-é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§)
2. [QdrantåŸºç¤çŸ¥è­˜](#2-qdrantåŸºç¤çŸ¥è­˜)
   - 2.1 [Qdrantã¨ã¯](#21-qdrantã¨ã¯)
   - 2.2 [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#22-ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
   - 2.3 [HNSWã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆè¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ï¼‰](#23-hnswã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢)
   - 2.4 [è·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹](#24-è·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹)
   - 2.5 [ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒã‚¤ãƒ³ãƒˆã®æ§‹é€ ](#25-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒã‚¤ãƒ³ãƒˆã®æ§‹é€ )
3. [ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²](#3-ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²)
   - 3.1 [Embeddingã®ç”Ÿæˆ](#31-embeddingã®ç”Ÿæˆ)
   - 3.2 [OpenAI Embedding APIã®ä½¿ç”¨](#32-openai-embedding-apiã®ä½¿ç”¨)
   - 3.3 [PointStructæ§‹é€ ã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰è¨­è¨ˆ](#33-pointstructæ§‹é€ ã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰è¨­è¨ˆ)
   - 3.4 [ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†](#34-ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†)
   - 3.5 [ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹](#35-ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
4. [é¡ä¼¼åº¦æ¤œç´¢](#4-é¡ä¼¼åº¦æ¤œç´¢)
   - 4.1 [ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®åŸºç¤](#41-ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®åŸºç¤)
   - 4.2 [æ¤œç´¢ãƒ•ãƒ­ãƒ¼](#42-æ¤œç´¢ãƒ•ãƒ­ãƒ¼)
   - 4.3 [ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ–](#43-ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ–)
   - 4.4 [æ¤œç´¢çµæœã®æ§‹é€ ](#44-æ¤œç´¢çµæœã®æ§‹é€ )
   - 4.5 [ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°](#45-ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°)
5. [RAGå¿œç”¨ï¼ˆQuery&Answerï¼‰](#5-ragå¿œç”¨queryanswer)
   - 5.1 [RAGã®åŸºæœ¬æ¦‚å¿µ](#51-ragã®åŸºæœ¬æ¦‚å¿µ)
   - 5.2 [Question=Queryã‹ã‚‰é¡ä¼¼Q/Aã‚’æ¤œç´¢](#52-questionqueryã‹ã‚‰é¡ä¼¼qaã‚’æ¤œç´¢)
   - 5.3 [æ¤œç´¢çµæœã«åŸºã¥ãAIå›ç­”ç”Ÿæˆ](#53-æ¤œç´¢çµæœã«åŸºã¥ãaiå›ç­”ç”Ÿæˆ)
   - 5.4 [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ](#54-ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ)
   - 5.5 [ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³](#55-ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³)
6. [æ¤œç´¢çµæœã®è©•ä¾¡](#6-æ¤œç´¢çµæœã®è©•ä¾¡)
   - 6.1 [ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ](#61-ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ)
   - 6.2 [é–¾å€¤è¨­å®šã®æŒ‡é‡](#62-é–¾å€¤è¨­å®šã®æŒ‡é‡)
   - 6.3 [è©•ä¾¡æŒ‡æ¨™](#63-è©•ä¾¡æŒ‡æ¨™)
   - 6.4 [æ¤œç´¢ç²¾åº¦ã®æ”¹å–„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯](#64-æ¤œç´¢ç²¾åº¦ã®æ”¹å–„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯)
7. [ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ](#7-ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ)
   - 7.1 [çµ±åˆã®ç›®çš„ã¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹](#71-çµ±åˆã®ç›®çš„ã¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹)
   - 7.2 [çµ±åˆãƒ•ãƒ­ãƒ¼](#72-çµ±åˆãƒ•ãƒ­ãƒ¼)
   - 7.3 [scroll_all_points_with_vectors()](#73-scroll_all_points_with_vectors)
   - 7.4 [merge_collections()](#74-merge_collections)
   - 7.5 [IDå†ç”Ÿæˆã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ](#75-idå†ç”Ÿæˆã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ)
   - 7.6 [UIæ“ä½œ](#76-uiæ“ä½œ)
8. [å‚è€ƒ](#8-å‚è€ƒ)
   - 8.1 [é–¢æ•°ä¸€è¦§](#81-é–¢æ•°ä¸€è¦§)
   - 8.2 [Qdrant API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](#82-qdrant-api-ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹)
   - 8.3 [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](#83-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)

---

## 1. æ¦‚è¦

### 1.1 æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ä»¥ä¸‹ã®3ã¤ã®æŠ€è¡“é ˜åŸŸã«ã¤ã„ã¦ã€Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ãŸçµ±åˆçš„ãªè§£èª¬ã‚’è¡Œã†ã€‚

1. **Qdrantã®åŸºç¤çŸ¥è­˜** - ãƒ™ã‚¯ãƒˆãƒ«DBã®ä»•çµ„ã¿ã€HNSWã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç­‰
2. **æ¤œç´¢ã®ä»•çµ„ã¿** - Embeddingã€é¡ä¼¼åº¦æ¤œç´¢ã€Query&Answerç”Ÿæˆ
3. **ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ** - è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®çµ±åˆæ©Ÿèƒ½ã¨é‹ç”¨

### 1.2 RAGã«ãŠã‘ã‚‹Qdrantã®å½¹å‰²

RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦Qdrantã¯æ–‡è„ˆæ¤œç´¢ã®ä¸­æ ¸ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚

```mermaid
flowchart LR
    subgraph Input
        A[ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•<br/>Query]
    end

    subgraph Processing
        B[Embedding<br/>OpenAI]
        C[Qdrant<br/>ãƒ™ã‚¯ãƒˆãƒ«DB]
        D[æ¤œç´¢çµæœ<br/>Top-K Q/A]
    end

    subgraph Generation
        E[LLM<br/>GPT-4oç­‰]
        F[å›ç­”ç”Ÿæˆ]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
```

**Qdrantã®å½¹å‰²:**
- Q/Aãƒšã‚¢ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’é«˜é€Ÿæ¤œç´¢
- ã‚³ã‚µã‚¤ãƒ³ãƒ™ã‚¯ãƒˆãƒ«é–“ã®é¡ä¼¼åº¦è¨ˆç®—
- é–¢é€£æ€§ã®é«˜ã„Q/Aã‚’åŠ¹ç‡çš„ã«æ¤œç´¢
- ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿

### 1.3 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

| ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² | ä¸»è¦é–¢æ•°/ã‚¯ãƒ©ã‚¹ |
|---------|------|----------------|
| `services/qdrant_service.py` | Qdrantæ“ä½œã‚µãƒ¼ãƒ“ã‚¹å±¤ | `embed_texts_for_qdrant()`, `merge_collections()` |
| `ui/pages/qdrant_search_page.py` | æ¤œç´¢UI | `show_qdrant_search_page()` |
| `ui/pages/qdrant_registration_page.py` | ç™»éŒ²ãƒ»çµ±åˆUI | `show_qdrant_registration_page()` |
| `ui/pages/qdrant_show_page.py` | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤ºUI | `show_qdrant_page()` |

---

## 2. QdrantåŸºç¤çŸ¥è­˜

### 2.1 Qdrantã¨ã¯

**Qdrant**ï¼ˆã‚¯ã‚¢ãƒ‰ãƒ©ãƒ³ãƒˆï¼‰ã¯Rustè£½ã®é«˜æ€§èƒ½ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§ã‚ã‚‹ã€‚

| é …ç›® | å†…å®¹ |
|------|------|
| é–‹ç™ºè¨€èª | Rust |
| ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | Apache 2.0 |
| ä¸»è¦ç”¨é€” | é¡ä¼¼åº¦æ¤œç´¢ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã€RAG |
| API | REST API / gRPC |
| ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ | Python, JavaScript, Rust, Go |

**ç‰¹å¾´:**
- **é«˜é€Ÿæ¤œç´¢**: HNSWã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢
- **ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: æ¡ä»¶ä»˜ãæ¤œç´¢ã®ã‚µãƒãƒ¼ãƒˆ
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®æŸ”è»Ÿãªã‚¹ã‚­ãƒ¼ãƒ
- **æ°¸ç¶šåŒ–**: ãƒ‡ã‚£ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸

### 2.2 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
flowchart TB
    subgraph Server["Qdrant Server"]
        subgraph API["API Layer"]
            REST["REST API<br/>:6333"]
            GRPC["gRPC API<br/>:6334"]
        end

        subgraph CM["Collection Manager"]
            CA["Collection A"]
            CB["Collection B"]
            CC["Collection C"]
        end

        subgraph Storage["Storage Layer"]
            HNSW["HNSW Index<br/>ãƒ™ã‚¯ãƒˆãƒ«"]
            Payload["Payload<br/>Storage"]
        end
    end

    REST --> CM
    GRPC --> CM
    CM --> Storage
```

**å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å½¹å‰²:**

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | å½¹å‰² |
|--------------|------|
| API Layer | REST/gRPCãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç† |
| Collection Manager | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®CRUDç®¡ç† |
| HNSW Index | ãƒ™ã‚¯ãƒˆãƒ«ã®è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ |
| Payload Storage | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰ã®æ ¼ç´ |

### 2.3 HNSWã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆè¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ï¼‰

**HNSWï¼ˆHierarchical Navigable Small Worldï¼‰** ã¯é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã®è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹ã€‚

#### HNSWã®æ§‹é€ 

```mermaid
flowchart TB
    subgraph L2["Layer 2 (æœ€ä¸Šä½ - ç–)"]
        N1((node))
        N2((node))
    end

    subgraph L1["Layer 1 (ä¸­é–“)"]
        N3((node))
        N4((node))
        N5((node))
        N6((node))
        N7((node))
    end

    subgraph L0["Layer 0 (æœ€ä¸‹ä½ - å¯†)"]
        N8((n))
        N9((n))
        N10((n))
        N11((n))
        N12((n))
        N13((n))
        N14((n))
        N15((n))
    end

    N1 --- N3
    N1 --- N4
    N2 --- N6
    N2 --- N7
    N3 --- N8
    N3 --- N9
    N4 --- N10
    N5 --- N11
    N6 --- N12
    N6 --- N13
    N7 --- N14
    N7 --- N15
```

**æ¢ç´¢ã®æµã‚Œ:** ä¸Šä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‹ã‚‰é–‹å§‹ã—ã€ã‚ˆã‚Šè¿‘ã„éš£æ¥ç‚¹ã‚’è¾¿ã£ã¦ä¸‹ä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¸ç§»å‹•

**æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :**

1. **æŒ¿å…¥æ™‚**: ãƒã‚¤ãƒ³ãƒˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãªæœ€å¤§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«é…ç½®ã•ã‚Œã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§æœ€è¿‘å‚ã¨æ¥ç¶š
2. **æ¢ç´¢æ™‚**: æœ€ä¸Šä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‹ã‚‰é–‹å§‹ã—ã€ã‚ˆã‚Šè¿‘ã„éš£æ¥ç‚¹ã‚’è¾¿ã£ã¦ä¸‹ä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¸ç§»å‹•
3. **çµæœ**: å®Œå…¨æ¢ç´¢ã§ã¯ãªã„ãŒã€éå¸¸ã«é«˜ã„ç²¾åº¦ã§é«˜é€Ÿãªæ¤œç´¢

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | å½±éŸ¿ |
|-----------|------|----------|------|
| `m` | å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ¥ç¶šæ•° | 16 | å¤§ãã„ã»ã©ç²¾åº¦å‘ä¸Šã€ãƒ¡ãƒ¢ãƒªå¢—åŠ  |
| `ef_construct` | æ§‹ç¯‰æ™‚ã®æ¢ç´¢å¹… | 100 | å¤§ãã„ã»ã©ç²¾åº¦å‘ä¸Šã€æ§‹ç¯‰æ™‚é–“å¢—åŠ  |
| `ef` | æ¤œç´¢æ™‚ã®æ¢ç´¢å¹… | 128 | å¤§ãã„ã»ã©ç²¾åº¦å‘ä¸Šã€æ¤œç´¢æ™‚é–“å¢—åŠ  |

**è¨ˆç®—é‡:**
- æŒ¿å…¥: O(log N)
- æ¤œç´¢: O(log N)
- å®Œå…¨æ¢ç´¢æ¯”: N=100ä¸‡ã§ç´„1000å€é«˜é€Ÿ

### 2.4 è·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹

QdrantãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹è·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹:

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | è¨ˆç®—å¼ | ç¯„å›² | ç”¨é€” |
|-----------|------|------|------|
| **Cosine** | 1 - (Aãƒ»B / \|A\|\|B\|) | 0ã€œ2 | ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦**ï¼ˆæ¨å¥¨ï¼‰** |
| **Dot** | -Aãƒ»B | -âˆã€œâˆ | éæ­£è¦åŒ–ãƒ™ã‚¯ãƒˆãƒ« |
| **Euclid** | âˆšÎ£(Ai-Bi)Â² | 0ã€œâˆ | ç©ºé–“è·é›¢ |

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã®è¨­å®š:**

```python
# services/qdrant_service.py:538-540
vectors_config = models.VectorParams(
    size=vector_size,
    distance=models.Distance.COSINE  # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
)
```

**ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’é¸æŠã™ã‚‹ç†ç”±:**
- ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã¯æ­£è¦åŒ–æ¸ˆã¿
- æ–‡ã®é•·ã•ã®é•ã„ã«å½±éŸ¿ã•ã‚Œã«ãã„
- æ„å‘³çš„é¡ä¼¼åº¦ã®è¨ˆæ¸¬ã«æœ€é©

### 2.5 ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒã‚¤ãƒ³ãƒˆã®æ§‹é€ 

#### ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆCollectionï¼‰

ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯é–¢é€£ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚‚ã®ã€‚

```python
# ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
client.create_collection(
    collection_name="qa_livedoor",
    vectors_config=models.VectorParams(
        size=1536,                    # ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•°
        distance=models.Distance.COSINE
    )
)
```

<details>
<summary>ğŸ“ create_or_recreate_collection_for_qdrant() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:534-562

def create_or_recreate_collection_for_qdrant(
    client: QdrantClient,
    name: str,
    recreate: bool = False,
    vector_size: int = 1536
):
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã¾ãŸã¯å†ä½œæˆ"""
    vectors_config = models.VectorParams(
        size=vector_size,
        distance=models.Distance.COSINE
    )

    if recreate:
        # æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆ
        try:
            client.delete_collection(collection_name=name)
            logger.info(f"æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤: {name}")
        except Exception:
            pass  # å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        client.create_collection(
            collection_name=name,
            vectors_config=vectors_config
        )
        logger.info(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ–°è¦ä½œæˆ: {name}")
    else:
        # å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ä½œæˆ
        try:
            client.get_collection(name)
            logger.info(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ—¢å­˜: {name}")
        except Exception:
            client.create_collection(
                collection_name=name,
                vectors_config=vectors_config
            )
            logger.info(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ–°è¦ä½œæˆ: {name}")

    # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆæ¤œç´¢åŠ¹ç‡åŒ–ï¼‰
    try:
        client.create_payload_index(
            name,
            field_name="domain",
            field_schema=models.PayloadSchemaType.KEYWORD
        )
    except Exception:
        pass  # æ—¢å­˜ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `recreate=True`: æ—¢å­˜å‰Šé™¤â†’æ–°è¦ä½œæˆï¼ˆå®Œå…¨ãƒªã‚»ãƒƒãƒˆï¼‰
- `recreate=False`: å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ä½œæˆï¼ˆè¿½åŠ ç™»éŒ²å‘ã‘ï¼‰
- `domain` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«KEYWORDã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é«˜é€ŸåŒ–ï¼‰
- COSINEè·é›¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨

</details>

#### ãƒã‚¤ãƒ³ãƒˆï¼ˆPointï¼‰

ãƒã‚¤ãƒ³ãƒˆã¯ãƒ™ã‚¯ãƒˆãƒ« + ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰ã®çµ„ã¿åˆã‚ã›ã€‚

```python
point = models.PointStruct(
    id=12345678901234,           # ä¸€æ„ã®IDï¼ˆ64bitæ•´æ•°ï¼‰
    vector=[0.023, -0.156, ...], # 1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«
    payload={                     # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰
        "question": "è³ªå•æ–‡",
        "answer": "å›ç­”æ–‡",
        "domain": "livedoor",
        "source": "a02_qa_pairs_livedoor.csv"
    }
)
```

**æ§‹é€ å›³:**

```
Collection: qa_livedoor
   Point 1
      id: 123456789
      vector: [0.023, -0.156, 0.089, ...]  (1536æ¬¡å…ƒ)
      payload: {"question": "...", "answer": "...", ...}
   Point 2
      id: 987654321
      vector: [0.045, 0.234, -0.012, ...]
      payload: {"question": "...", "answer": "...", ...}
   ... (N points)
```

---

## 3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²

### 3.1 Embeddingã®ç”Ÿæˆ

Q/Aãƒšã‚¢ã‚’Qdrantã«ç™»éŒ²ã™ã‚‹ã¾ã§ã®ãƒ•ãƒ­ãƒ¼:

```mermaid
flowchart TB
    A["qa_output/*.csv<br/>(question, answer)"]
    B["load_csv_for_qdrant()<br/>åˆ—åå¤‰æ›ãƒ»é‡è¤‡é™¤å»ãƒ»ä»¶æ•°åˆ¶é™"]
    C["build_inputs_for_embedding()<br/>question + answer çµåˆ"]
    D["embed_texts_for_qdrant()<br/>OpenAI APIãƒ»ãƒãƒƒãƒå‡¦ç†"]
    E["build_points_for_qdrant()<br/>IDç”Ÿæˆãƒ»ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰è¨­å®š"]
    F["upsert_points_to_qdrant()<br/>ãƒãƒƒãƒå‡¦ç†ãƒ»Qdrantç™»éŒ²"]

    A -->|CSVèª­è¾¼| B
    B -->|ãƒ†ã‚­ã‚¹ãƒˆçµåˆ| C
    C -->|Embedding| D
    D -->|ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰| E
    E -->|ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ| F
```

### 3.2 OpenAI Embedding APIã®ä½¿ç”¨

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ `text-embedding-3-small` ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

```python
# services/qdrant_service.py:469-531
def embed_texts_for_qdrant(
    texts: List[str],
    model: str,
    batch_size: int = 128
) -> List[List[float]]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†ã§Embeddingã«å¤‰æ›"""
    enc = tiktoken.get_encoding("cl100k_base")
    client = OpenAI()

    MAX_TOKENS_PER_REQUEST = 8000

    # ç©ºæ–‡å­—åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    valid_texts = []
    valid_indices = []
    for i, text in enumerate(texts):
        if text and text.strip():
            valid_texts.append(text)
            valid_indices.append(i)

    # ãƒãƒƒãƒå‡¦ç†ã§APIå‘¼ã³å‡ºã—
    for i, text in enumerate(valid_texts):
        text_tokens = len(enc.encode(text))

        if current_tokens + text_tokens > MAX_TOKENS_PER_REQUEST:
            # ãƒãƒƒãƒå‡¦ç†
            resp = client.embeddings.create(model=model, input=current_batch)
            valid_vecs.extend([d.embedding for d in resp.data])
            current_batch = []
            current_tokens = 0

        current_batch.append(text)
        current_tokens += text_tokens

    # æœ€çµ‚ãƒãƒƒãƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦å†é…ç½®
    # ç©ºæ–‡å­—åˆ—ã®ä½ç½®ã«ã¯ [0.0] * 1536 ã®ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«
```

<details>
<summary>ğŸ“ embed_texts_for_qdrant() å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:469-531

def embed_texts_for_qdrant(
    texts: List[str], model: str, batch_size: int = 128
) -> List[List[float]]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†ã§Embeddingã«å¤‰æ›"""
    enc = tiktoken.get_encoding("cl100k_base")
    client = OpenAI()

    MAX_TOKENS_PER_REQUEST = 8000

    # ç©ºæ–‡å­—åˆ—ãƒ»ç©ºç™½ã®ã¿ã®æ–‡å­—åˆ—ã‚’é™¤å¤–
    valid_texts = []
    valid_indices = []
    for i, text in enumerate(texts):
        if text and text.strip():
            valid_texts.append(text)
            valid_indices.append(i)

    if not valid_texts:
        logger.warning("å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºæ–‡å­—åˆ—ã§ã™ã€‚ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã—ã¾ã™ã€‚")
        return [[0.0] * 1536] * len(texts)

    # æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    valid_vecs: List[List[float]] = []
    current_batch = []
    current_tokens = 0
    batch_count = 0

    for i, text in enumerate(valid_texts):
        text_tokens = len(enc.encode(text))

        if text_tokens > MAX_TOKENS_PER_REQUEST:
            raise ValueError(
                f"Single text at index {valid_indices[i]} has {text_tokens} tokens, "
                f"which exceeds MAX_TOKENS_PER_REQUEST ({MAX_TOKENS_PER_REQUEST}). "
            )

        if current_tokens + text_tokens > MAX_TOKENS_PER_REQUEST:
            if current_batch:
                batch_count += 1
                resp = client.embeddings.create(model=model, input=current_batch)
                valid_vecs.extend([d.embedding for d in resp.data])
                current_batch = []
                current_tokens = 0

        current_batch.append(text)
        current_tokens += text_tokens

    if current_batch:
        batch_count += 1
        resp = client.embeddings.create(model=model, input=current_batch)
        valid_vecs.extend([d.embedding for d in resp.data])

    # å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’å†é…ç½®
    vecs: List[List[float]] = []
    valid_vec_idx = 0
    for i in range(len(texts)):
        if i in valid_indices:
            vecs.append(valid_vecs[valid_vec_idx])
            valid_vec_idx += 1
        else:
            vecs.append([0.0] * 1536)  # ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«

    return vecs
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `tiktoken.get_encoding("cl100k_base")`: OpenAIåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ç”¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
- `MAX_TOKENS_PER_REQUEST = 8000`: APIåˆ¶é™ã«å¯¾å¿œã—ãŸãƒãƒƒãƒåˆ†å‰²
- ç©ºæ–‡å­—åˆ—ä½ç½®ã« `[0.0] * 1536` ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«é…ç½®ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ç¶­æŒï¼‰
- å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚º: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«å¿œã˜ã¦æœ€é©ãªãƒãƒƒãƒã‚’æ§‹ç¯‰

</details>

**Embeddingè¨­å®š:**

| é …ç›® | å€¤ |
|------|-----|
| ãƒ¢ãƒ‡ãƒ« | text-embedding-3-small |
| æ¬¡å…ƒæ•° | 1536 |
| æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ | 8191 |
| ãƒãƒƒãƒä¸Šé™ | 8000ãƒˆãƒ¼ã‚¯ãƒ³/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ |

### 3.3 PointStructæ§‹é€ ã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰è¨­è¨ˆ

```python
# services/qdrant_service.py:565-589
def build_points_for_qdrant(
    df: pd.DataFrame,
    vectors: List[List[float]],
    domain: str,
    source_file: str
) -> List[models.PointStruct]:
    """Qdrantãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰"""

    now_iso = datetime.now(timezone.utc).isoformat()
    points: List[models.PointStruct] = []

    for i, row in enumerate(df.itertuples(index=False)):
        payload = {
            "domain": domain,
            "question": getattr(row, "question"),
            "answer": getattr(row, "answer"),
            "source": os.path.basename(source_file),
            "created_at": now_iso,
            "schema": "qa:v1"
        }

        # IDã®ç”Ÿæˆï¼ˆ64ãƒ“ãƒƒãƒˆæ­£æ•´æ•°ï¼‰
        pid = abs(hash(f"{domain}-{source_file}-{i}")) & 0x7FFFFFFFFFFFFFFF

        points.append(models.PointStruct(
            id=pid,
            vector=vectors[i],
            payload=payload
        ))

    return points
```

**ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ¼ãƒï¼ˆqa:v1ï¼‰:**

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | å‹ | èª¬æ˜ |
|-----------|-----|------|
| domain | string | ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆlivedoor, cc_news, customï¼‰ |
| question | string | è³ªå•æ–‡ |
| answer | string | å›ç­”æ–‡ |
| source | string | ã‚½ãƒ¼ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«å |
| created_at | string | ç™»éŒ²æ—¥æ™‚ï¼ˆISO 8601ï¼‰ |
| schema | string | ã‚¹ã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ³ |

### 3.4 ãƒãƒƒãƒã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå‡¦ç†

```python
# services/qdrant_service.py:592-603
def upsert_points_to_qdrant(
    client: QdrantClient,
    collection: str,
    points: List[models.PointStruct],
    batch_size: int = 128
) -> int:
    """ãƒã‚¤ãƒ³ãƒˆã‚’Qdrantã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ"""
    count = 0
    for chunk in batched(points, batch_size):
        client.upsert(collection_name=collection, points=chunk)
        count += len(chunk)
    return count
```

**upsertã®å‹•ä½œ:**
- åŒä¸€IDãŒå­˜åœ¨ â†’ ä¸Šæ›¸ãæ›´æ–°
- æ–°è¦ID â†’ æ–°è¦æŒ¿å…¥
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çš„ãªå‹•ä½œï¼ˆãƒãƒƒãƒå˜ä½ï¼‰

### 3.5 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

æ¤œç´¢åŠ¹ç‡åŒ–ã®ãŸã‚ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã€‚

```python
# services/qdrant_service.py:556-562
client.create_payload_index(
    name,
    field_name="domain",
    field_schema=models.PayloadSchemaType.KEYWORD
)
```

**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¨®åˆ¥:**

| ç¨®åˆ¥ | ç”¨é€” |
|--------|------|
| KEYWORD | å®Œå…¨ä¸€è‡´æ¤œç´¢ï¼ˆdomain, sourceï¼‰ |
| INTEGER | æ•°å€¤æ¤œç´¢ï¼ˆtimestampï¼‰ |
| TEXT | å…¨æ–‡æ¤œç´¢ï¼ˆquestion, answerï¼‰ |

---

## 4. é¡ä¼¼åº¦æ¤œç´¢

### 4.1 ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®åŸºç¤

**ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦**ã¯2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã®è§’åº¦ã®ä½™å¼¦ã‚’è¨ˆç®—ã™ã‚‹ã€‚

#### è¨ˆç®—å¼

```
cos(Î¸) = (A Â· B) / (|A| Ã— |B|)

        Î£(Ai Ã— Bi)
     =
       âˆšÎ£(AiÂ²) Ã— âˆšÎ£(BiÂ²)
```

#### å›³è§£

```
        ^ Y
        |
            B (é¡ä¼¼åº¦é«˜)
           /
          /  Î¸ (å°ã•ã„è§’åº¦)
         /
        /________ A     â†’ X


            C (é¡ä¼¼åº¦ä½)
           \
            \  Î¸' (å¤§ãã„è§’åº¦)
             \

cos(Î¸) â‰ˆ 1.0  â†’ é¡ä¼¼åº¦ãŒé«˜ã„
cos(Î¸) â‰ˆ 0.0  â†’ é¡ä¼¼åº¦ãªã—ï¼ˆç›´äº¤ï¼‰
cos(Î¸) â‰ˆ -1.0 â†’ é¡ä¼¼åº¦ãŒä½ã„ï¼ˆåå¯¾ï¼‰
```

#### ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã§ã®æ„å‘³

| ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ | æ„å‘³ | ä¾‹ |
|--------------|------|-----|
| 0.95ã€œ1.00 | éå¸¸ã«é¡ä¼¼ | åŒç¾©æ–‡ |
| 0.80ã€œ0.94 | é«˜ã„é¡ä¼¼åº¦ | åŒç¾©èª+è¨€ã„æ›ãˆ |
| 0.50ã€œ0.79 | ä¸­ç¨‹åº¦ | åŒç¾©ã®ãƒˆãƒ”ãƒƒã‚¯ç¯„å›²å†… |
| 0.00ã€œ0.49 | ä½ã„é¡ä¼¼åº¦ | æ„å‘³çš„ã«ç„¡é–¢ä¿‚ |
| < 0 | è² ã®ç›¸é–¢ | åå¯¾ã®æ„å‘³ |

### 4.2 æ¤œç´¢ãƒ•ãƒ­ãƒ¼

```mermaid
flowchart TB
    A["ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•<br/>Pythonã®ä½¿ã„æ–¹ã¯"]
    B["embed_query_for_search()<br/>OpenAI Embedding API<br/>1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ"]
    C["client.search()<br/>HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢<br/>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—<br/>Top-Kçµæœå–å¾—"]
    D["æ¤œç´¢çµæœ<br/>ã‚¹ã‚³ã‚¢ãƒ»IDãƒ»ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰"]

    A -->|å…¥åŠ›| B
    B -->|query_vector| C
    C -->|ScoredPoint| D
```

### 4.3 ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ–

```python
# services/qdrant_service.py:610-619
def embed_query_for_search(
    query: str,
    model: str = "text-embedding-3-small",
    dims: Optional[int] = None
) -> List[float]:
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    client = OpenAI()
    kwargs = {"model": model, "input": query}
    if dims:
        kwargs["dimensions"] = dims
    resp = client.embeddings.create(**kwargs)
    return resp.data[0].embedding
```

**æ¤œç´¢å‘¼ã³å‡ºã—:**

```python
# ui/pages/qdrant_search_page.py:184-186
hits = client.search(
    collection_name=collection,
    query_vector=qvec,
    limit=topk
)
```

<details>
<summary>ğŸ“ æ¤œç´¢ãƒ•ãƒ­ãƒ¼ å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# ui/pages/qdrant_search_page.py:160-200

# æ¤œç´¢å®Ÿè¡Œ
if do_search and query.strip():
    try:
        client = QdrantClient(url=qdrant_url)

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã—ãŸåŸ‹ã‚è¾¼ã¿è¨­å®šã‚’å–å¾—
        collection_config = COLLECTION_EMBEDDINGS_SEARCH.get(
            collection, {"model": "text-embedding-3-small", "dims": 1536}
        )
        embedding_model = collection_config["model"]
        embedding_dims = collection_config.get("dims")

        # ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        with st.spinner("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
            qvec = embed_query_for_search(query, embedding_model, embedding_dims)

        # Qdrantã§æ¤œç´¢
        with st.spinner("æ¤œç´¢ä¸­..."):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", DeprecationWarning)
                hits = client.search(
                    collection_name=collection,
                    query_vector=qvec,
                    limit=topk
                )

        # æ¤œç´¢çµæœã‚’DataFrameã«å¤‰æ›
        rows = []
        for h in hits:
            row_data = {
                "ã‚¹ã‚³ã‚¢": f"{h.score:.4f}",
                "è³ªå•": h.payload.get("question", "N/A") if h.payload else "N/A",
                "å›ç­”": h.payload.get("answer", "N/A") if h.payload else "N/A",
                "ã‚½ãƒ¼ã‚¹": h.payload.get("source", "N/A") if h.payload else "N/A",
            }
            rows.append(row_data)

        df_results = pd.DataFrame(rows)
        st.dataframe(df_results, use_container_width=True, hide_index=True)

    except Exception as e:
        st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `COLLECTION_EMBEDDINGS_SEARCH`: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¯ã®åŸ‹ã‚è¾¼ã¿è¨­å®šã‚’å–å¾—
- `embed_query_for_search()`: ã‚¯ã‚¨ãƒªã‚’1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
- `client.search()`: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§Top-Kæ¤œç´¢
- çµæœã‚’DataFrameã§è¡¨å½¢å¼è¡¨ç¤º

</details>

### 4.4 æ¤œç´¢çµæœã®æ§‹é€ 

```python
# Qdrant search()ã®æˆ»ã‚Šå€¤
[
    ScoredPoint(
        id=1234567890123456789,
        score=0.8923,              # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        payload={
            "question": "Pythonã§ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹ã«ã¯",
            "answer": "è§’æ‹¬å¼§[]ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™...",
            "domain": "livedoor",
            "source": "a02_qa_pairs_livedoor.csv",
            "created_at": "2025-11-28T10:30:00Z",
            "schema": "qa:v1"
        },
        vector=None  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šã€é€šå¸¸ã¯è¿”ã•ãªã„
    ),
    ScoredPoint(
        id=9876543210987654321,
        score=0.8456,
        payload={...}
    ),
    ...
]
```

### 4.5 ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

ç‰¹å®šæ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸæ¤œç´¢:

```python
# domainã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
hits = client.search(
    collection_name="qa_corpus",
    query_vector=qvec,
    query_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="domain",
                match=models.MatchValue(value="livedoor")
            )
        ]
    ),
    limit=10
)

# è¤‡æ•°æ¡ä»¶ï¼ˆANDï¼‰
query_filter=models.Filter(
    must=[
        models.FieldCondition(key="domain", match=models.MatchValue(value="livedoor")),
        models.FieldCondition(key="schema", match=models.MatchValue(value="qa:v1"))
    ]
)

# ORæ¡ä»¶
query_filter=models.Filter(
    should=[
        models.FieldCondition(key="domain", match=models.MatchValue(value="livedoor")),
        models.FieldCondition(key="domain", match=models.MatchValue(value="cc_news"))
    ]
)
```

---

## 5. RAGå¿œç”¨ï¼ˆQuery&Answerï¼‰

### 5.1 RAGã®åŸºæœ¬æ¦‚å¿µ

**RAGï¼ˆRetrieval-Augmented Generationï¼‰** ã¯æ¤œç´¢æ‹¡å¼µç”Ÿæˆã®æ‰‹æ³•ã§ã€LLMã®å›ç­”ã«å¤–éƒ¨çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã€‚

**å¾“æ¥ã®LLMã®èª²é¡Œ:**
- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„æƒ…å ±ã«ã¯å›ç­”ã§ããªã„
- ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆèª¤ã£ãŸæƒ…å ±ã®ç”Ÿæˆï¼‰
- æœ€æ–°æƒ…å ±ã¸ã®æœªå¯¾å¿œ

**RAGã«ã‚ˆã‚‹è§£æ±º:**
- ãƒ™ã‚¯ãƒˆãƒ«DBã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢
- æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦LLMã«æä¾›
- æ ¹æ‹ ã«åŸºã¥ãå›ç­”ç”Ÿæˆ

### 5.2 Question=Queryã‹ã‚‰é¡ä¼¼Q/Aã‚’æ¤œç´¢

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ï¼ˆQueryï¼‰ã‚’ä»¥ä¸‹ã®æµã‚Œã§å‡¦ç†ã™ã‚‹:

```mermaid
flowchart TB
    A["ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•<br/>Pythonã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã«ã¯"]
    B["Embedding<br/>OpenAI text-embedding-3-small<br/>1536æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ"]
    C["Qdrantæ¤œç´¢<br/>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§Top-Kæ¤œç´¢"]
    D["é¡ä¼¼Q/Aå–å¾—<br/>1. score: 0.89<br/>2. score: 0.82<br/>3. score: 0.78"]
    E["æœ€ä¸Šä½ã®Q/Aã‚’ä½¿ç”¨"]

    A --> B
    B --> C
    C --> D
    D --> E
```

### 5.3 æ¤œç´¢çµæœã«åŸºã¥ãAIå›ç­”ç”Ÿæˆ

```python
# ui/pages/qdrant_search_page.py:238-265
best_hit = hits[0]
question = best_hit.payload.get("question", "")
answer = best_hit.payload.get("answer", "")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
qa_prompt = (
    "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦"
    "æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„\n\n"
    f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
    f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
    f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
    f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
)

# OpenAI APIå‘¼ã³å‡ºã—
oai_client = OpenAI()
oai_resp = oai_client.responses.create(
    model="gpt-4o-mini",
    input=qa_prompt
)
generated_answer = oai_resp.output_text
```

<details>
<summary>ğŸ“ RAGå¿œç­”ç”Ÿæˆ å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# ui/pages/qdrant_search_page.py:238-265

# æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœã§AIå¿œç­”ç”Ÿæˆ
if hits:
    best_hit = hits[0]
    question = best_hit.payload.get("question", "")
    answer = best_hit.payload.get("answer", "")

    # AIå¿œç­”ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    qa_prompt = (
        "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦ã€"
        "æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
        f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
        f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
        f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
    )

    # OpenAI APIå‘¼ã³å‡ºã—ï¼ˆresponses.createï¼‰
    with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
        oai_client = OpenAI()
        oai_resp = oai_client.responses.create(
            model="gpt-4o-mini",
            input=qa_prompt
        )
        generated_answer = getattr(oai_resp, "output_text", None) or ""

    if generated_answer.strip():
        st.markdown("**AIå¿œç­”:**")
        st.write(generated_answer)
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `best_hit = hits[0]`: æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœã‚’ä½¿ç”¨
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ¤œç´¢ã‚¹ã‚³ã‚¢ãƒ»è³ªå•ãƒ»å›ç­”ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å«ã‚ã‚‹
- `responses.create()`: OpenAI Responses APIã§AIå¿œç­”ç”Ÿæˆ
- `getattr(oai_resp, "output_text", None)`: å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã®å®‰å…¨ãªå–å¾—

</details>

### 5.4 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

**RAGç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ :**

```mermaid
flowchart TB
    subgraph Prompt["ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ "]
        SYS["ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º<br/>æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”"]
        QRY["ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•<br/>query"]
        CTX["æ¤œç´¢çµæœã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ<br/>score / question / answer"]
    end

    LLM["LLM<br/>GPT-4o"]
    ANS["å›ç­”ç”Ÿæˆ"]

    SYS --> LLM
    QRY --> LLM
    CTX --> LLM
    LLM --> ANS
```

### 5.5 ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³

```mermaid
sequenceDiagram
    participant User as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant UI as Streamlit UI
    participant OAI_Emb as OpenAI Embedding
    participant Qdrant as Qdrant
    participant OAI_LLM as OpenAI LLM

    User->>UI: è³ªå•å…¥åŠ› "Pythonã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã«ã¯"
    UI->>OAI_Emb: embed_query_for_search(query)
    OAI_Emb-->>UI: query_vector [1536æ¬¡å…ƒ]

    UI->>Qdrant: search(collection, query_vector, limit=5)
    Note over Qdrant: HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢<br/>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    Qdrant-->>UI: hits[] (Top-5 Q/A)

    UI->>UI: æœ€ä¸Šä½ã®Q/Aã‚’é¸æŠ
    UI->>UI: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰

    UI->>OAI_LLM: responses.create(prompt)
    OAI_LLM-->>UI: generated_answer

    UI->>User: æ¤œç´¢çµæœ + AIå›ç­”ã‚’è¡¨ç¤º
```

---

## 6. æ¤œç´¢çµæœã®è©•ä¾¡

### 6.1 ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ

Qdrantã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ:

| ã‚¹ã‚³ã‚¢ç¯„å›² | æ„å‘³ | æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |
|-----------|------|---------------|
| **0.90ã€œ1.00** | æ¥µã‚ã¦é«˜ã„é¡ä¼¼åº¦ | ãã®ã¾ã¾å›ç­”ã¨ã—ã¦ä½¿ç”¨å¯èƒ½ |
| **0.80ã€œ0.89** | é«˜ã„é¡ä¼¼åº¦ | AIå›ç­”ã§è£œå®Œæ¨å¥¨ |
| **0.70ã€œ0.79** | ä¸­ç¨‹åº¦ã®é¡ä¼¼åº¦ | å‚è€ƒæƒ…å ±ã¨ã—ã¦è¡¨ç¤º |
| **0.60ã€œ0.69** | ä½ã„é¡ä¼¼åº¦ | é–¢é€£æƒ…å ±ã¨ã—ã¦è¡¨ç¤º |
| **0.60æœªæº€** | é–¢é€£æ€§ãŒä½ã„ | è­¦å‘Šã—ã¦åˆ¥ã®æ¤œç´¢ã‚’ä¿ƒã™ |

### 6.2 é–¾å€¤è¨­å®šã®æŒ‡é‡

**é–¾å€¤ã®è¨­å®š:**

```python
# ã‚¹ã‚³ã‚¢é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
hits = client.search(
    collection_name=collection,
    query_vector=qvec,
    score_threshold=0.7,  # 0.7æœªæº€ã¯é™¤å¤–
    limit=10
)
```

**é–¾å€¤è¨­å®šã®ç›®å®‰:**

| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | æ¨å¥¨é–¾å€¤ | ç†ç”± |
|------------|---------|------|
| FAQæ¤œç´¢ | 0.85ã€œ0.90 | é«˜ç²¾åº¦å¿…é ˆ |
| ä¸€èˆ¬Q&A | 0.70ã€œ0.80 | ãƒãƒ©ãƒ³ã‚¹é‡è¦– |
| æ¢ç´¢çš„æ¤œç´¢ | 0.50ã€œ0.60 | åºƒç¯„å›²å¯¾è±¡ |

### 6.3 è©•ä¾¡æŒ‡æ¨™

**æ¤œç´¢ç²¾åº¦ã®è©•ä¾¡:**

| æŒ‡æ¨™ | å®šç¾© | è¨ˆç®—å¼ |
|------|------|---------|
| **Precision@K** | Top-Kä¸­ã®æ­£è§£ç‡ | æ­£è§£æ•° / K |
| **Recall@K** | å…¨æ­£è§£ä¸­ã®æ¤œç´¢ç‡ | æ¤œç´¢æ­£è§£æ•° / å…¨æ­£è§£æ•° |
| **MRR** | æœ€åˆã®æ­£è§£ã®ä½ç½® | 1 / æ­£è§£é †ä½ |
| **NDCG** | é †ä½ã®é‡ã¿ä»˜ã‘è©•ä¾¡ | DCG / IDCG |

**æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã®ç°¡æ˜“è©•ä¾¡:**

```python
def evaluate_search_quality(query, expected_answer, hits):
    """æ¤œç´¢ã®ç°¡æ˜“è©•ä¾¡"""
    if not hits:
        return {"found": False, "score": 0, "rank": -1}

    for rank, hit in enumerate(hits, 1):
        retrieved_answer = hit.payload.get("answer", "")
        # å›ç­”ã®é¡ä¼¼åº¦åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if expected_answer.lower() in retrieved_answer.lower():
            return {
                "found": True,
                "score": hit.score,
                "rank": rank,
                "mrr": 1.0 / rank
            }

    return {"found": False, "score": hits[0].score, "rank": -1}
```

### 6.4 æ¤œç´¢ç²¾åº¦ã®æ”¹å–„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

#### 1. ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼ˆQuery Expansionï¼‰

```python
def expand_query(query: str) -> List[str]:
    """åŒç¾©èªã§ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µ"""
    expansions = [query]
    # åŒç¾©èªè¾æ›¸ã‚„LLMã§æ‹¡å¼µ
    # ä¾‹: "Python ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼" â†’ ["Python ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼", "Python opené–¢æ•°", "Python read"]
    return expansions
```

#### 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢

```mermaid
flowchart TB
    Q["ã‚¯ã‚¨ãƒª"]
    V["ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"]
    K["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"]
    S1["ã‚¹ã‚³ã‚¢1"]
    S2["ã‚¹ã‚³ã‚¢2"]
    M["ã‚¹ã‚³ã‚¢çµ±åˆ"]
    R["æœ€çµ‚çµæœ"]

    Q --> V
    Q --> K
    V --> S1
    K --> S2
    S1 --> M
    S2 --> M
    M --> R
```

#### 3. ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°

```python
def rerank_results(query: str, hits: List[ScoredPoint]) -> List[ScoredPoint]:
    """æ¤œç´¢çµæœã‚’LLMã§ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
    # Cross-encoderã‚„LLMã‚’ä½¿ç”¨ã—ã¦é †ä½ã‚’èª¿æ•´
    pass
```

---

## 7. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ

### 7.1 çµ±åˆã®ç›®çš„ã¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ**ã¯è¤‡æ•°ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹æ©Ÿèƒ½ã€‚

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**

| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | èª¬æ˜ |
|-------------|------|
| **çµ±åˆæ¤œç´¢** | è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ¨ªæ–­ã—ã¦æ¤œç´¢ |
| **æ®µéšçš„çµ±åˆ** | ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ®µéšçš„ã«æœ¬ç•ªçµ±åˆ |
| **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰** | å¤ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ã®ç§»è¡Œ |
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ** | åˆ†æ•£ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å¾©å…ƒ |

### 7.2 çµ±åˆãƒ•ãƒ­ãƒ¼

```mermaid
flowchart TB
    subgraph Source["ã‚½ãƒ¼ã‚¹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"]
        CA["Collection A<br/>1,500 points"]
        CB["Collection B<br/>2,000 points"]
    end

    SA["scroll()"]
    SB["scroll()"]

    FETCH["å…¨ãƒã‚¤ãƒ³ãƒˆå–å¾—<br/>with_payload=True<br/>with_vectors=True"]

    REGEN["IDå†ç”Ÿæˆ + ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ<br/>æ–°IDç”Ÿæˆãƒ»_source_collectionè¿½åŠ "]

    MERGED["çµ±åˆãƒã‚¤ãƒ³ãƒˆãƒªã‚¹ãƒˆ"]

    UPSERT["upsert()"]

    TARGET["Integrated Collection<br/>integration_collection_a<br/>3,500 points"]

    CA --> SA
    CB --> SB
    SA --> FETCH
    SB --> FETCH
    FETCH --> REGEN
    REGEN --> MERGED
    MERGED --> UPSERT
    UPSERT --> TARGET
```

### 7.3 scroll_all_points_with_vectors()

ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å…¨ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«å«ã‚€ï¼‰ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚

```python
# services/qdrant_service.py:626-672
def scroll_all_points_with_vectors(
    client: QdrantClient,
    collection_name: str,
    batch_size: int = 100,
    progress_callback: Optional[callable] = None,
) -> List[models.Record]:
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰å…¨ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«å«ã‚€ï¼‰ã‚’å–å¾—"""
    all_points = []
    offset = None

    # ç·ä»¶æ•°ã‚’å–å¾—
    collection_info = client.get_collection(collection_name)
    total_points = collection_info.points_count

    while True:
        points, next_offset = client.scroll(
            collection_name=collection_name,
            limit=batch_size,
            offset=offset,
            with_payload=True,
            with_vectors=True,  # ãƒ™ã‚¯ãƒˆãƒ«ã‚‚å–å¾—
        )

        if not points:
            break

        all_points.extend(points)

        if progress_callback:
            progress_callback(len(all_points), total_points)

        if next_offset is None:
            break

        offset = next_offset

    return all_points
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----|---------|------|
| client | QdrantClient | - | Qdrantã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ |
| collection_name | str | - | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å |
| batch_size | int | 100 | 1å›ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§å–å¾—ã™ã‚‹ä»¶æ•° |
| progress_callback | callable | None | é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ |

### 7.4 merge_collections()

è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã™ã‚‹é–¢æ•°ã€‚

```python
# services/qdrant_service.py:675-779
def merge_collections(
    client: QdrantClient,
    source_collections: List[str],
    target_collection: str,
    recreate: bool = True,
    vector_size: int = 1536,
    progress_callback: Optional[callable] = None,
) -> Dict[str, Any]:
    """è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã—ã¦æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ç™»éŒ²"""

    result = {
        "source_collections": source_collections,
        "target_collection": target_collection,
        "points_per_collection": {},
        "total_points": 0,
        "success": False,
        "error": None,
    }

    # ã‚¹ãƒ†ãƒƒãƒ—1: çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
    create_or_recreate_collection_for_qdrant(
        client, target_collection, recreate, vector_size
    )

    # ã‚¹ãƒ†ãƒƒãƒ—2: å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒã‚¤ãƒ³ãƒˆå–å¾—
    all_points = []
    for src_collection in source_collections:
        points = scroll_all_points_with_vectors(client, src_collection)
        result["points_per_collection"][src_collection] = len(points)

        # ãƒã‚¤ãƒ³ãƒˆIDå†ç”Ÿæˆ
        for i, point in enumerate(points):
            payload = dict(point.payload) if point.payload else {}
            payload["_source_collection"] = src_collection
            payload["_original_id"] = point.id

            new_id = abs(
                hash(f"{target_collection}-{src_collection}-{point.id}-{i}")
            ) & 0x7FFFFFFFFFFFFFFF

            all_points.append(
                models.PointStruct(
                    id=new_id,
                    vector=point.vector,
                    payload=payload,
                )
            )

    # ã‚¹ãƒ†ãƒƒãƒ—3: çµ±åˆå…ˆã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
    for chunk in batched(all_points, 128):
        client.upsert(collection_name=target_collection, points=chunk)

    result["total_points"] = len(all_points)
    result["success"] = True

    return result
```

**æˆ»ã‚Šå€¤:**

```python
{
    "source_collections": ["qa_livedoor_a02", "qa_cc_news_a02"],
    "target_collection": "integration_qa_livedoor_a02",
    "points_per_collection": {
        "qa_livedoor_a02": 1500,
        "qa_cc_news_a02": 2000
    },
    "total_points": 3500,
    "success": True,
    "error": None
}
```

### 7.5 IDå†ç”Ÿæˆã¨ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ

**IDå†ç”Ÿæˆã®ç†ç”±:**
- è¤‡æ•°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§IDãŒé‡è¤‡ã™ã‚‹å¯èƒ½æ€§
- çµ±åˆå¾Œã®ä¸€æ„æ€§ã‚’ç¢ºä¿

**IDç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯:**

```python
new_id = abs(
    hash(f"{target_collection}-{src_collection}-{point.id}-{i}")
) & 0x7FFFFFFFFFFFFFFF
```

**ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ‹¡å¼µ:**

```python
# çµ±åˆå‰
{
    "question": "è³ªå•æ–‡",
    "answer": "å›ç­”æ–‡",
    "domain": "livedoor",
    "source": "a02_qa_pairs_livedoor.csv",
    "created_at": "2025-11-28T10:30:00Z",
    "schema": "qa:v1"
}

# çµ±åˆå¾Œï¼ˆè¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
{
    "question": "è³ªå•æ–‡",
    "answer": "å›ç­”æ–‡",
    "domain": "livedoor",
    "source": "a02_qa_pairs_livedoor.csv",
    "created_at": "2025-11-28T10:30:00Z",
    "schema": "qa:v1",
    "_source_collection": "qa_livedoor_a02",  # è¿½åŠ 
    "_original_id": 1234567890123456789       # è¿½åŠ 
}
```

### 7.6 UIæ“ä½œ

**Streamlit UIã§ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆæ“ä½œ:**

```
1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆã€ã‚’é¸æŠ

2. çµ±åˆå…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ

    â˜‘ qa_livedoor_a02 (1,500 ãƒã‚¤ãƒ³ãƒˆ)
    â˜‘ qa_cc_news_a02 (2,000 ãƒã‚¤ãƒ³ãƒˆ)
    â˜ qa_corpus (500 ãƒã‚¤ãƒ³ãƒˆ)

   â€» 2ã¤ä»¥ä¸Šé¸æŠå¿…é ˆ

3. çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åè¨­å®š

    æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å:
    [integration_qa_livedoor_a02    ]
    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: integration_{å…ˆé ­å}


4. ã€Œã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯

5. é€²æ—è¡¨ç¤º
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%
   çµ±åˆå®Œäº†: 3,500ä»¶

6. çµæœç¢ºèª
   - qa_livedoor_a02: 1,500ä»¶
   - qa_cc_news_a02: 2,000ä»¶
   - åˆè¨ˆ: 3,500ä»¶
```

<details>
<summary>ğŸ“ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆUI å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# ui/pages/qdrant_registration_page.py:531-592

if run_merge:
    st.session_state["merge_logs"] = []
    add_merge_log(f"ğŸ”— çµ±åˆå‡¦ç†é–‹å§‹")
    add_merge_log(f"çµ±åˆå…ƒ: {', '.join(selected_collections)}")
    add_merge_log(f"çµ±åˆå…ˆ: {merge_collection_name}")

    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
    progress_bar = progress_placeholder.progress(0)

    def progress_callback(message: str, current: int, total: int):
        """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        add_merge_log(message)
        if total > 0:
            progress_bar.progress(current / total)
        status_placeholder.text(message)

    try:
        # çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œ
        result = merge_collections(
            client=client,
            source_collections=selected_collections,
            target_collection=merge_collection_name,
            recreate=recreate_merge,
            progress_callback=progress_callback,
        )

        if result["success"]:
            add_merge_log("ğŸ‰ çµ±åˆå‡¦ç†å®Œäº†ï¼")

            # å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å–å¾—ä»¶æ•°ã‚’ãƒ­ã‚°
            for src_name, count in result["points_per_collection"].items():
                add_merge_log(f"  - {src_name}: {count:,} ä»¶")

            add_merge_log(f"åˆè¨ˆ: {result['total_points']:,} ä»¶")

            st.success(
                f"âœ… {result['total_points']:,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ "
                f"'{merge_collection_name}' ã«çµ±åˆã—ã¾ã—ãŸ"
            )

            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            stats = get_collection_stats(client, merge_collection_name)
            if stats:
                st.divider()
                st.subheader("ğŸ“Š çµ±åˆçµæœ")
                st.json(stats)

        else:
            add_merge_log(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
            st.error(f"çµ±åˆã‚¨ãƒ©ãƒ¼: {result['error']}")

    except Exception as e:
        add_merge_log(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    finally:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
        progress_placeholder.empty()
        status_placeholder.empty()
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `progress_callback`: 3æ®µéšã®é€²æ—é€šçŸ¥ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆâ†’ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆï¼‰
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¯ã®å–å¾—ä»¶æ•°ã‚’è©³ç´°ãƒ­ã‚°ã«è¨˜éŒ²
- æˆåŠŸ/å¤±æ•—ã®çµæœã‚’è©³ç´°ã«è¡¨ç¤º
- `finally` ã§ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ç¢ºå®Ÿã«ã‚¯ãƒªã‚¢

</details>

---

## 8. å‚è€ƒ

### 8.1 é–¢æ•°ä¸€è¦§

| æ©Ÿèƒ½ | ãƒ•ã‚¡ã‚¤ãƒ« | é–¢æ•°/ã‚¯ãƒ©ã‚¹ | è¡Œç•ªå· |
|-----|---------|------------|-------|
| Qdrantè¨­å®š | services/qdrant_service.py | QDRANT_CONFIG | 38-46 |
| ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ | services/qdrant_service.py | QdrantHealthChecker | 91-137 |
| ãƒ‡ãƒ¼ã‚¿å–å¾— | services/qdrant_service.py | QdrantDataFetcher | 144-329 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ | services/qdrant_service.py | get_collection_stats() | 336-374 |
| å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾— | services/qdrant_service.py | get_all_collections() | 377-397 |
| CSVèª­ã¿è¾¼ã¿ | services/qdrant_service.py | load_csv_for_qdrant() | 431-459 |
| åŸ‹ã‚è¾¼ã¿å…¥åŠ›æ§‹ç¯‰ | services/qdrant_service.py | build_inputs_for_embedding() | 462-466 |
| åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ | services/qdrant_service.py | embed_texts_for_qdrant() | 469-531 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ | services/qdrant_service.py | create_or_recreate_collection_for_qdrant() | 534-562 |
| ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ | services/qdrant_service.py | build_points_for_qdrant() | 565-589 |
| ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ | services/qdrant_service.py | upsert_points_to_qdrant() | 592-603 |
| æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«åŒ– | services/qdrant_service.py | embed_query_for_search() | 610-619 |
| å…¨ãƒã‚¤ãƒ³ãƒˆå–å¾— | services/qdrant_service.py | scroll_all_points_with_vectors() | 626-672 |
| ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ | services/qdrant_service.py | merge_collections() | 675-779 |
| æ¤œç´¢UI | ui/pages/qdrant_search_page.py | show_qdrant_search_page() | 30-279 |
| ç™»éŒ²UI | ui/pages/qdrant_registration_page.py | show_qdrant_registration_page() | 39-600 |

### 8.2 Qdrant API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**ä¸»è¦ãªQdrant Client API:**

| ãƒ¡ã‚½ãƒƒãƒ‰ | èª¬æ˜ | ä¾‹ |
|---------|------|-----|
| `create_collection()` | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ | `client.create_collection(name, vectors_config)` |
| `delete_collection()` | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤ | `client.delete_collection(name)` |
| `get_collection()` | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±å–å¾— | `client.get_collection(name)` |
| `get_collections()` | å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ | `client.get_collections()` |
| `upsert()` | ãƒã‚¤ãƒ³ãƒˆç™»éŒ²/æ›´æ–° | `client.upsert(collection, points)` |
| `search()` | ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ | `client.search(collection, query_vector, limit)` |
| `scroll()` | ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å–å¾— | `client.scroll(collection, limit, offset)` |
| `delete()` | ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤ | `client.delete(collection, points_selector)` |
| `create_payload_index()` | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ | `client.create_payload_index(collection, field)` |

### 8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š

| æ“ä½œ | æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º | ç†ç”± |
|------|----------------|------|
| Embedding | 8000ãƒˆãƒ¼ã‚¯ãƒ³/ãƒãƒƒãƒ | OpenAI APIåˆ¶é™ |
| Qdrant upsert | 128ãƒã‚¤ãƒ³ãƒˆ/ãƒãƒƒãƒ | ãƒ¡ãƒ¢ãƒª/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒãƒ©ãƒ³ã‚¹ |
| scrollå–å¾— | 100ãƒã‚¤ãƒ³ãƒˆ/ãƒãƒƒãƒ | å¿œç­”é€Ÿåº¦ |

#### HNSWãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

```python
# ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆæ™‚ã«è¨­å®š
client.create_collection(
    collection_name="high_precision_collection",
    vectors_config=models.VectorParams(
        size=1536,
        distance=models.Distance.COSINE
    ),
    hnsw_config=models.HnswConfigDiff(
        m=32,              # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ16 â†’ ç²¾åº¦å‘ä¸Š
        ef_construct=200,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100 â†’ æ§‹ç¯‰ç²¾åº¦å‘ä¸Š
    )
)
```

#### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›®å®‰

```
ãƒ¡ãƒ¢ãƒª â‰ˆ ãƒã‚¤ãƒ³ãƒˆæ•° Ã— (ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•° Ã— 4ãƒã‚¤ãƒˆ + ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰å¹³å‡ã‚µã‚¤ã‚º + HNSWã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰)

ä¾‹: 100ä¸‡ãƒã‚¤ãƒ³ãƒˆã€1536æ¬¡å…ƒã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰1KB
    â‰ˆ 1,000,000 Ã— (1536 Ã— 4 + 1024 + 100)
    â‰ˆ 7.3 GB
```

### 8.4 QdrantHealthCheckerï¼ˆæ¥ç¶šãƒã‚§ãƒƒã‚¯ï¼‰

Qdrantã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã€‚

<details>
<summary>ğŸ“ QdrantHealthChecker å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰</summary>

```python
# services/qdrant_service.py:91-137

class QdrantHealthChecker:
    """Qdrantã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""

    def __init__(self, debug_mode: bool = False):
        self.debug_mode = debug_mode
        self.client = None

    def check_port(self, host: str, port: int, timeout: float = 2.0) -> bool:
        """ãƒãƒ¼ãƒˆãŒé–‹ã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((host, port))
            sock.close()
            return result == 0
        except Exception as e:
            if self.debug_mode:
                logger.error(f"Port check failed for {host}:{port}: {e}")
            return False

    def check_qdrant(self) -> Tuple[bool, str, Optional[Dict]]:
        """Qdrantæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        start_time = time.time()

        # ã¾ãšãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        if not self.check_port(QDRANT_CONFIG["host"], QDRANT_CONFIG["port"]):
            return False, "Connection refused (port closed)", None

        try:
            self.client = QdrantClient(url=QDRANT_CONFIG["url"], timeout=5)

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—
            collections = self.client.get_collections()

            metrics = {
                "collection_count": len(collections.collections),
                "collections": [c.name for c in collections.collections],
                "response_time_ms": round((time.time() - start_time) * 1000, 2),
            }

            return True, "Connected", metrics

        except Exception as e:
            error_msg = str(e)
            if self.debug_mode:
                error_msg = f"{error_msg}\n{traceback.format_exc()}"
            return False, error_msg, None
```

**ä½¿ç”¨ä¾‹:**

```python
checker = QdrantHealthChecker(debug_mode=False)
is_connected, message, metrics = checker.check_qdrant()

if is_connected:
    print(f"âœ… {message}")
    print(f"   ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {metrics['collection_count']}")
    print(f"   å¿œç­”æ™‚é–“: {metrics['response_time_ms']}ms")
else:
    print(f"âŒ {message}")
```

**ãƒã‚¤ãƒ³ãƒˆ:**
- `check_port()`: ã‚½ã‚±ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã§ãƒãƒ¼ãƒˆé–‹æ”¾ç¢ºèªï¼ˆé«˜é€Ÿãªäº‹å‰ãƒã‚§ãƒƒã‚¯ï¼‰
- `timeout=2.0`: ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã¯2ç§’ã€APIæ¥ç¶šã¯5ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
- `response_time_ms`: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ è¨ˆæ¸¬ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨ï¼‰
- `debug_mode=True`: ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ™‚ã«ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹è¡¨ç¤º

</details>

---

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [doc/06_embedding_qdrant.md](./06_embedding_qdrant.md) - Embeddingãƒ»Qdrantç™»éŒ²ãƒ»æ¤œç´¢ã®è©³ç´°
- [doc/rag_qa_pair_qdrant.md](./rag_qa_pair_qdrant.md) - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [Qdrantå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://qdrant.tech/documentation/) - å…¬å¼ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹