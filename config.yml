# config.yml（改修後）

models:
  default: "gpt-5-mini"
  available:
    - "gpt-4o"
    - "gpt-4o-mini"
    - "gpt-4.1"
    - "gpt-4.1-mini"
    - "o3"
    - "o4-mini"
    - "gpt-5"
    - "gpt-5-mini"
    - "gpt-5-nano"

  audio_default: "tts-1"

  categories:
    frontier: ["gpt-5", "gpt-5-mini", "gpt-5-nano"]              # GPT-5 系（最新）  [oai_citation:13‡OpenAI Platform](https://platform.openai.com/docs/models/compare?utm_source=chatgpt.com)
    reasoning: ["o3", "o4-mini", "o1", "o1-pro"]                  # o系推論モデル   [oai_citation:14‡OpenAI Platform](https://platform.openai.com/docs/models/o1?utm_source=chatgpt.com)
    deep_research: ["o3-deep-research", "o4-mini-deep-research"]  # 深い調査用      [oai_citation:15‡OpenAI Platform](https://platform.openai.com/docs/models/o3-deep-research?utm_source=chatgpt.com)
    standard: ["gpt-4o", "gpt-4o-mini", "gpt-4.1", "gpt-4.1-mini"]# 安定の汎用      [oai_citation:16‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-4o?utm_source=chatgpt.com)
    vision: ["gpt-5", "gpt-4o", "gpt-4o-mini"]                    # 画像入力対応    [oai_citation:17‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-5-chat-latest?utm_source=chatgpt.com)
    audio:
      - "gpt-4o-audio-preview"
      - "gpt-4o-mini-audio-preview"
      - "gpt-4o-transcribe"
      - "gpt-4o-mini-transcribe"  # 追加                  [oai_citation:18‡OpenAI Platform](https://platform.openai.com/docs/models/gpt-4o-mini-transcribe?utm_source=chatgpt.com)
      - "gpt-4o-mini-tts"
      - "tts-1"
      - "tts-1-hd"
      - "whisper-1"
    realtime: ["gpt-4o-realtime-preview", "gpt-4o-mini-realtime-preview"]  # Realtime   [oai_citation:19‡OpenAI Platform](https://platform.openai.com/docs/models?utm_source=chatgpt.com)
    image: ["gpt-image-1", "dall-e-3"]                                     # 画像生成   [oai_citation:20‡OpenAI Platform](https://platform.openai.com/docs/models/dall-e-3?utm_source=chatgpt.com)
    search: ["gpt-4o-search-preview", "gpt-4o-mini-search-preview"]        # Web検索    [oai_citation:21‡OpenAI Platform](https://platform.openai.com/docs/models/compare?utm_source=chatgpt.com)
    open_weight: ["gpt-oss-120b", "gpt-oss-20b"]                            # Open weight
    embeddings: ["text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"]
    moderation: ["omni-moderation-latest"]

samples:
  images:
    nature: "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
  prompts: {}
  audio:
    tts_example: "こんにちは、これはテキスト読み上げのテストです。"
    voice_agent_greeting: "音声エージェントのテストです。何かお手伝いできることはありますか？"
    transcription_test: "This is a test for speech-to-text functionality."

audio:
  voices: ["alloy", "nova", "echo", "onyx", "shimmer"]
  supported_formats: ["*.mp3", "*.wav", "*.m4a"]
  tts_max_chars: 4096
  voice_agent_system_prompt: "You are a friendly Japanese voice assistant. Respond in concise Japanese (≤2 sentences)."
  tts:
    default_voice: "alloy"
    streaming_enabled: true
    quality_settings:
      tts-1: "speed_optimized"
      tts-1-hd: "quality_optimized"
      gpt-4o-mini-tts: "gpt4o_enhanced"
  stt:
    response_format: "text"
    language: "ja"
    max_file_size_mb: 25
  realtime:
    default_format: "pcm16"
    vad_enabled: true
    sample_rate: 16000

model_pricing:
  tts-1:
    input: 0.015
    output: 0.0
  tts-1-hd:
    input: 0.030
    output: 0.0
  gpt-4o-mini-tts:
    input: 0.025
    output: 0.0
  whisper-1:
    input: 0.006
    output: 0.0
  gpt-4o-transcribe:
    input: 0.010
    output: 0.0

# =====================================================
# Gemini API Configuration (Gemini 3 Migration)
# =====================================================
gemini:
  # LLM設定
  default_model: "gemini-2.0-flash"
  available_models:
    - "gemini-3-pro-preview"       # 最新Pro（思考モード対応）
    - "gemini-2.5-flash-preview"   # 高速・思考対応
    - "gemini-2.0-flash"           # 安定版（推奨デフォルト）
    - "gemini-1.5-pro"             # レガシー
    - "gemini-1.5-flash"           # レガシー高速

  # Embedding設定（Gemini 3アドバンテージ: 3072次元）
  embedding:
    model: "gemini-embedding-001"
    dimensions: 3072               # Gemini 3最大精度（OpenAI: 1536）
    task_types:
      - "RETRIEVAL_DOCUMENT"       # ドキュメントインデックス用
      - "RETRIEVAL_QUERY"          # クエリ用
      - "SEMANTIC_SIMILARITY"      # 類似度計算用
      - "CLASSIFICATION"           # 分類用

  # 思考レベル設定（Gemini 3 / 2.5対応モデル用）
  thinking:
    default_level: "low"           # "low" または "high"
    supported_models:
      - "gemini-3-pro-preview"
      - "gemini-2.5-flash-preview"

  # 生成パラメータ
  generation:
    default_temperature: 1.0
    default_max_tokens: 8192
    top_p: 0.95
    top_k: 40

  # 料金（$/1M tokens）
  pricing:
    gemini-3-pro-preview:
      input: 1.25
      output: 10.0
    gemini-2.5-flash-preview:
      input: 0.15
      output: 3.50
    gemini-2.0-flash:
      input: 0.10
      output: 0.40
    gemini-1.5-pro:
      input: 1.25
      output: 5.00
    gemini-1.5-flash:
      input: 0.075
      output: 0.30
    gemini-embedding-001:
      input: 0.00         # 無料
      output: 0.00

  # レート制限
  rate_limits:
    requests_per_minute: 60
    tokens_per_minute: 1000000

# =====================================================
# Provider Configuration
# =====================================================
provider:
  # デフォルトプロバイダー設定
  default_llm: "gemini"            # "openai" or "gemini"
  default_embedding: "gemini"      # "openai" or "gemini"

  # OpenAI設定
  openai:
    embedding_model: "text-embedding-3-small"
    embedding_dims: 1536

  # Gemini設定（上記geminiセクション参照）
  # embedding_dims: 3072

# =====================================================
# Qdrant Configuration
# =====================================================
qdrant:
  # コレクション設定
  collection:
    default_name: "rag_documents"
    distance_metric: "Cosine"      # Cosine, Euclid, or Dot

  # ベクトル次元数（プロバイダーに応じて設定）
  vector_dims:
    gemini: 3072                   # Gemini Embedding次元
    openai: 1536                   # OpenAI Embedding次元

  # インデックス設定
  index:
    on_disk: false
    quantization: null             # "scalar" or "binary" for optimization
